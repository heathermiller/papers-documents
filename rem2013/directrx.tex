% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\usepackage{listings}
\usepackage{url}
\usepackage{bcprules}
\usepackage{prooftree}
\usepackage{multicol}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[normalem]{ulem}

\lstdefinelanguage{Scala}%
{morekeywords={abstract,case,catch,char,class,%
    def,else,extends,final,%
    if,import,%
    match,module,new,null,object,override,package,private,protected,%
    public,return,super,this,throw,trait,try,type,val,var,with,implicit,%
    macro,sealed,%
  },%
  sensitive,%
  morecomment=[l]//,%
  morecomment=[s]{/*}{*/},%
  morestring=[b]",%
  morestring=[b]',%
  showstringspaces=false%
}[keywords,comments,strings]%

\lstset{language=Scala,%
  mathescape=true,%
  columns=[c]fixed,%
  basewidth={0.5em, 0.40em},%
  basicstyle=\tt,%
  xleftmargin=0.0cm
}

% comments and notes
\newcommand{\comment}[1]{}
\newcommand{\note}[1]{{\bf $\clubsuit$ #1 $\spadesuit$}}
\newcommand{\ifreport}[1]{#1}
%\newcommand{\ifreport}[1]{}

\newcommand{\todo}{{\bf \colorbox{red}{\color{white}TODO:}}}
\newcommand{\ie}{{\em i.e.,~}}
\newcommand{\eg}{{\em e.g.,~}}
\newcommand{\term}[1]{\mbox{\texttt{#1}}}
\newcommand{\itl}[1]{\mbox{\textit{#1}}}

% commas and semicolons
\newcommand{\comma}{,\,}
\newcommand{\commadots}{\comma \ldots \comma}
\newcommand{\semi}{;\mbox{;};}
\newcommand{\semidots}{\semi \ldots \semi}

% spacing
\newcommand{\gap}{\quad\quad}
\newcommand{\biggap}{\quad\quad\quad}
\newcommand{\nextline}{\\ \\}
\newcommand{\htabwidth}{0.5cm}
\newcommand{\tabwidth}{1cm}
\newcommand{\htab}{\hspace{\htabwidth}}
\newcommand{\tab}{\hspace{\tabwidth}}
\newcommand{\linesep}{\ \hrulefill \ \smallskip}

\newcommand{\sectionline}{%
  \nointerlineskip \vspace{\baselineskip}%
  \hspace{\fill}\rule{0.5\linewidth}{.7pt}\hspace{\fill}%
  \par\nointerlineskip \vspace{\baselineskip}
}

% figures
\newcommand{\figurebox}[1]
        {\fbox{\begin{minipage}{\textwidth} #1 \medskip\end{minipage}}}
\newcommand{\twofig}[3]
        {\begin{figure*}[t]#3\ \hrulefill\
        \caption{\label{#1}#2}\end{figure*}}
\newcommand{\boxfig}[3]
        {\begin{figure*}\figurebox{#3\caption{\label{#1}#2}}\end{figure*}}
\newcommand{\figref}[1]
        {Figure~\ref{#1}}

% \newcommand{\note}[1]{{\bf $\clubsuit$ #1 $\spadesuit$}}
% %\newcommand{\note}[1]{}
% \newcommand{\comment}[1]{}

% arrays
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bda}{\[\ba}
\newcommand{\eda}{\ea\]}
\newcommand{\ei}{\end{array}}
\newcommand{\bcases}{\left\{\begin{array}{ll}}
\newcommand{\ecases}{\end{array}\right.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Language abstraction commands     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Relations
% Subtype
\newcommand{\sub}{<:}
% Type assignment
\newcommand{\typ}{:}
% reduction
\newcommand{\reduces}{\;\rightarrow\;}
% well-formedness
\newcommand{\wf}{\;\mbox{\textbf{wf}}}

%% Operators
% Type selection
\newcommand{\tsel}{\#}
% Function type
\newcommand{\tfun}{\rightarrow}
\newcommand{\dfun}[3]{(#1\!:\!#2) \Rightarrow #3}
% Conjunction
\newcommand{\tand}{\wedge}
% Disjunction
\newcommand{\tor}{\vee}
% Singleton type suffix
\newcommand{\sing}{.\textbf{type}}

%% Syntax
% Header for typing rules
\newcommand{\judgement}[2]{{\bf #1} \hfill \fbox{#2}}
% Refinement
\newcommand{\refine}[2]{\left\{#1 \Rightarrow #2 \right\}}
% Field definitions
\newcommand{\ldefs}[1]{\left\{#1\right\}}
% Member sequences
\newcommand{\seq}[1]{\overline{#1}}
% Lambda
\newcommand{\dabs}[3]{(#1\!:\!#2)\Rightarrow #3}
\newcommand{\abs}[3]{\lambda #1\!:\!#2.#3}
% Application
\newcommand{\app}[2]{#1\;#2}
% Substitution
\newcommand{\subst}[3]{[#1/#2]#3}
% Object creation
\newcommand{\new}[3]{\textbf{val }#1 = \textbf{new }#2 ;\; #3}
%\renewcommand{\new}[3]{#1 \leftarrow #2 \,\textbf{in}\, #3}
% Field declaration
\newcommand{\Ldecl}[3]{#1 \typ #2..#3}%{#1 \operatorname{>:} #2 \operatorname{<:} #3}
\newcommand{\ldecl}[2]{#1 \typ #2}
% Top and Bottom
\newcommand{\Top}{\top}%{\textbf{Top}}
\newcommand{\Bot}{\bot}%\textbf{Bot}}
% Environment extension
\newcommand{\envplus}[1]{\uplus \{ #1 \}}

\newcommand{\aframe}[3]{\langle #1, #2 \rangle ^{#3}}

\newcommand{\reduce}[4]{#1, #2 \;\leadsto\; #3, #4}
\newcommand{\reducebreak}[4]{#1, #2 \\ \;\leadsto\; #3, #4}

\newcommand{\fsreduce}[4]{#1, #2 \;\twoheadrightarrow\; #3, #4}
\newcommand{\fsreducebreak}[4]{#1, #2 \\ \;\twoheadrightarrow\; #3, #4}

\newcommand{\sreduce}[6]{#1, #2, #3 \;\longrightarrow\; #4, #5, #6}
\newcommand{\sreducebreak}[6]{#1, #2, #3 \\ \;\longrightarrow\; #4, #5, #6}

\begin{document}

\title{RAY: Towards Direct-Style Reactive Streams}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Philipp Haller\\
       \affaddr{Typesafe, Inc.}\\
       \email{philipp.haller@typesafe.com}
% 2nd. author
\alignauthor
Heather Miller\\
       \affaddr{EPFL}\\
       \email{heather.miller@epfl.ch}
}

\maketitle
\begin{abstract}

Languages like F\#, C\#, and recently also Scala, provide ``async'' extensions
which aim to make asynchronous programming easier by avoiding an inversion of
control that is inherent in traditional callback-based programming models (for
the purpose of this paper called the ``Async'' model). This paper outlines a
novel approach to integrate the Async model with observable streams of the
Reactive Extensions model which is best-known from the .NET platform, and of
which popular implementations exist for Java, Ruby, and other widespread
languages. We outline the translation of ``Reactive Async'' programs to
efficient state machines, in a way that generalizes the state machine
translation of regular Async programs. Finally, we sketch a formalization of
the Reactive Async model in terms of a small-step operational semantics.

\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

%\terms{Theory}

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\section{Introduction}

Asynchronous programming has been a challenge for a long time. A multitude of
programming models has been proposed that aim to simplify the task.
Interestingly, there are elements of a convergence arising, at least with
respect to the basic building blocks: futures and promises have begun to play
a more and more important role in a number of languages like Java, C++,
ECMAScript, and Scala.

The Async extensions of F\#~\cite{SymePL11}, C\#~\cite{FormalizingAsync}, and
Scala~\cite{ScalaAsyncSIP} provide language support for programming with
futures (or ``tasks''), by avoiding an inversion of control that is inherent
in designs based on callbacks. However, these extensions are so far only
applicable to futures or future-like abstractions. In this paper we consider
an integration of the Async model with a richer underlying abstraction, the
observable streams of the Reactive Extensions model.~\cite{RxCACM} A reactive
stream is a stream of {\em observable events} which an arbitrary number of
{\em observers} can subscribe to. The set of possible event patterns of
observable streams is strictly greater than those of futures. A stream can (a) produce zero or more regular events, (b) complete normally, or (c) complete with an error (it's even possible for a stream to never complete.) Given the richer substrate of reactive streams, the Async model has to be
generalized in several dimensions.

This paper makes the following contributions:
\begin{itemize}
  \item A design and proposal to integrate the Async model and the Reactive Extensions model in the context
    of the Scala Async project~\cite{ScalaAsync} developed at Typesafe and proposed for adoption in 
    mainline Scala~\cite{ScalaAsyncSIP};
  \item An operational semantics of the proposed programming model. Our operational semantics generalizes the 
    formal model presented in~\cite{FormalizingAsync} for C\#'s async/await.
\end{itemize}


\section{Background}

\subsection{Scala Async}\label{sec:scala-async}

Scala Async provides constructs that aim to facilitate programming with
asynchronous events in Scala. The introduced constructs are inspired to a
large extent by extensions that have been introduced in C\# version 5~\cite{Hejlsberg:2011:CPL} in a
similar form. The goal is to enable expressing
asynchronous code in ``direct style'', i.e., in a familiar blocking style
where suspending operations look as if they were blocking while at the same
time using efficient non-blocking APIs under the hood.

In Scala, an immediate consequence is that non-blocking code using Scala's
futures API~\cite{ScalaFuturesSIP} does not have to resort to (a) low-level
callbacks, or (b) higher-order functions like \verb|map| and \verb|flatMap|. While the
latter have great composability properties, they can appear unnatural when
used to express the regular control flow of a program.

The main methods provided by Scala Async, \verb|async| and \verb|await|, have
the following type signatures:

\begin{lstlisting}
def async[T](body: => T): Future[T]
def await[T](future: Future[T]): T
\end{lstlisting}

Given the above definitions, \verb|async| and \verb|await| ``cancel each other
out:''

\begin{lstlisting}
await(async { <expr> }) = <expr>
\end{lstlisting}

This ``equation'' paints a grossly over-simplified picture, though, since the
actual operational behavior is much more complicated: \verb|async| typically
schedules its argument expression to run asynchronously on a thread pool;
moreover, \verb|await| may only be invoked within a syntactically enclosing
\verb|async| block.

In practice, the \verb|async| and \verb|await| methods are used as follows
(this example is adopted from the SIP proposal~\cite{ScalaAsyncSIP}):

\lstset{numbers=left,xleftmargin=2em}
\begin{lstlisting}
val futureDOY: Future[Response] =
  WS.url("http://api.day-of-year/today").get

val futureDaysLeft: Future[Response] =
  WS.url("http://api.days-left/today").get

val respFut = async {
  val dayOfYear = await(futureDOY).body
  val daysLeft = await(futureDaysLeft).body
  Ok("" + dayOfYear + ": " +
          daysLeft + " days left!")
}
\end{lstlisting}

Line 1 and 4 define two futures obtained as results of asynchronous requests
to two hypothetical web services using an API inspired by Play Framework (for
the purpose of this example, the definition of type \verb|Response| is
unimportant). The await on line 8 causes the execution of the \verb|async|
block to suspend until \verb|futureDOY| is completed (with a successful result
or with an exception). When the future is completed successfully, its result
is bound to the \verb|dayOfYear| local variable, and the execution of the
\verb|async| block is resumed. When the future is completed with an exception
(for example, because of a timeout), the invocation of \verb|await| re-throws
the exception that the future was completed with. In turn, this completes
future \verb|respFut| with the same exception. Likewise, the \verb|await| on
line 9 suspends the execution of the \verb|async| block until
\verb|futureDaysLeft| is completed.


\subsection{Reactive Extensions}

The Rx programming model is based on two interface traits: \verb|Observable|
and \verb|Observer|. \verb|Observable| represents observable streams, i.e.,
streams that produce a sequence of events. These events can be observed by
registering an \verb|Observer| with the \verb|Observable|. The \verb|Observer|
provides methods which are invoked for each of the kinds of events produced by
the \verb|Observable|. In Scala, the two traits can be defined as shown in
Figure~\ref{fig:observable-observer}.

\begin{figure}[ht!]
  \centering
  \lstset{numbers=none,xleftmargin=0em}
  \begin{lstlisting}
  trait Observable[T] {
    def subscribe(obs: Observer[T]): Closable
  }

  trait Observer[T] extends (Try[T] => Unit) {
    def apply(tr: Try[T]): Unit
    def onNext(v: T) = apply(Success(v))
    def onFailure(t: Throwable) = apply(Failure(t))
    def onDone(): Unit
  }
  \end{lstlisting}
  \caption{The \texttt{Observable} and \texttt{Observer} traits.}
  \label{fig:observable-observer}
\end{figure}

The idea of the \verb|Observer| is that it can respond to three different
kinds of events, (1) the next regular event (\verb|onNext|), (2) a failure
(\verb|onFailure|), and (3) the end of the observable stream (\verb|onDone|).
Thus, the two traits constitute a variation of the classic subject/observer
pattern~\cite{EugsterFGK03}. Note that \verb|Observable|'s \verb|subscribe|
method returns a \verb|Closable|; it has only a single abstract \verb|close|
method which removes the subscription from the observable. The next listing
shows an example implementation.

Note that in our Scala version the \verb|Observer| trait extends the function
type \verb|Try[T] => Unit|. \verb|Try[T]| is a simple container type which
supports heap-based exception handling (as opposed to the traditional stack-
based exception handling using expressions like \verb|try-catch-finally|.)
There are two subclasses of \verb|Try[T]|: \verb|Success| (encapsulating a
value of type \verb|T|) and \verb|Failure| (encapsulating an exception). Given
the above definition, a concrete \verb|Observer| only has to provide
implementations for the \verb|apply| and \verb|onDone| methods. Since
\verb|apply| takes a parameter of type \verb|Try[T]| its implementation
handles the \verb|onNext| and \verb|onFailure| events all at once (in Scala,
this is tyically done by pattern matching on \verb|tr| with cases for
\verb|Success| and \verb|Failure|).

The \verb|Observer| and \verb|Observable| traits are used as follows. For
example, here is a factory method for creating an observable from a text input
field of typical GUI toolkits (this example is adapted from~\cite{RxCACM}):

\lstset{numbers=none,xleftmargin=0em}
\begin{lstlisting}
def textChanges(tf: JTextField): Observable[String] =
  new ObservableBase[String] {
    def subscribe(o: Observer[String]) = {
      val l = new DocumentListener {
        def changedUpdate(e: DocumentEvent) = {
          o.onNext(tf.getText())
        }
      }
      tf.addDocumentListener(l)
      new Closable() {
        def close() = {
          tf.removeDocumentListener(l)
        }
      }
    }
  }
\end{lstlisting}

This newly-defined \verb|textChanges| combinator can be used with other Rx
combinators as follows:

\begin{lstlisting}
textChanges(input)
.flatMap(word => completions(word))
.subscribe(observeChanges(output))
\end{lstlisting}

We start with the observable created using the \verb|textChanges| method from
above. Then we use the \verb|flatMap| combinator (called \verb|Select| in C\#)
to transform the observable into a new observable which is a stream of
completions for a given word (a string). On the resulting observable we call
\verb|subscribe| to register a consumer: \verb|observeChanges| creates an
observer which outputs all received events to the \verb|output| stream. (The
shown example suffers from a problem explained in~\cite{RxCACM} which
motivates the use of an additional \verb|Switch| combinator which is omitted
here for brevity.)


\section{The Reactive Async Model}

This Section provides an (example-driven) overview of the Reactive Async Model
which integrates the Async Model and the Reactive Extensions Model.

The basic idea is to generalize the Async model, so that it can be used not
only with futures, but also with observable streams. This means, we need
constructs that can create observables, as opposed to only futures (like
\verb|async|), and we need ways to wait for more events than just the
completion of a future. Essentially, it should be possible to await all kinds
of events produced by an observable stream. Analogous to \verb|await| which
waits for the completion event of a future, we introduce variations like
\verb|awaitNext| and \verb|awaitNextOrDone| to express waiting for the events
of an observable stream.

\subsection{A first example}

The following example shows how to await a fixed number of events of a stream
in the Reactive Async Model:

\begin{lstlisting}
val obs = rasync {
  var events = List[Int]()
  while (events.size < 5) {
    val event = awaitNext(stream)
    events = event :: events
  }
  Some(events)
}
\end{lstlisting}

Note that we are using the \verb|rasync| construct; it is a generalized
version of the \verb|async| construct of Section~\ref{sec:scala-async} which
additionally supports methods to await events of observable streams.

In the above example, the invocation of \verb|awaitNext| suspends the
\verb|rasync| block until the producer of \verb|stream| calls \verb|onNext| on
its observers. The argument of this \verb|onNext| call (the next event) is
returned as a result from \verb|awaitNext|. The result of \verb|rasync|,
\verb|obs|, has type \verb|Observable[List[Int]]|. Once the body of
\verb|rasync| has been fully evaluated, \verb|obs| publishes two events:
first, an \verb|onNext| event which carries \verb|events| (the list with five
elements), and second, an \verb|onDone| event; it is not possible for
\verb|obs| to publish further events.

Note that the result of an \verb|rasync| block has a type of the form
\verb|Option[T]|; in the case where this optional value is empty
(\verb|None|), only an \verb|onDone| event is published as a result of fully
evaluating the \verb|rasync| block. (It is, however, possible to publish other
events beforehand, as shown in the following sections.) Otherwise, the
semantics of \verb|rasync| is analogous to the behavior of a regular
\verb|async| block: when its body has been fully evaluated, the future, which
is the result of \verb|async|, is completed and further changes to the state
of the future are impossible.


\subsection{Awaiting the end of a stream}

Sometimes it is not known statically how many events a stream might still
publish. One might want to collect all events until the stream is done
(finished publishing events). In this case it is necessary to have a way to
wait for either of two events: the stream publishes a next event, or the
stream is done. This can be supported using a method \verb|awaitNextOrDone|
which returns an \verb|Option[T]| when applied to an \verb|Observable[T]|:

\begin{lstlisting}
rasync {
  var events: List[Int] = List()
  var next: Option[Int] = awaitNextOrDone(stream)
  while (next.nonEmpty) {
    events = next.get :: events
    next = awaitNextOrDone(stream)
  }
  Some(events)
}
\end{lstlisting}

In the above example, the body of \verb|rasync| repeatedly waits for the given
\verb|stream| to publish either a next event or to reach its end, using
\verb|awaitNextOrDone|. As long as the \verb|stream| continues to publish
events (in which case \verb|next| of type \verb|Option[Int]| is non-empty),
each event is prepended to the \verb|events| list; this list is the single
event that the observable which is, in turn, created by \verb|rasync|
publishes (once the body of \verb|rasync| has been fully evaluated).


\subsection{Creating more complex streams}

The streams created by \verb|rasync| in the previous sections are rather
simple: after consuming events from other streams only a single interesting
event is published on the created stream (by virtue of reaching the end of the
\verb|rasync| block). In this section, we explain how more complex streams can
be created in the Reactive Async Model.

\begin{figure}[ht!]
  \centering
  \begin{lstlisting}
  val forwarder = rasync[Int] {
    var next: Option[Int] =
      awaitNextOrDone(stream)

    while (next.nonEmpty) {
      yieldNext(next.get)
      next = awaitNextOrDone(stream)
    }
    None
  }
  \end{lstlisting}
  \caption{A simple forwarder stream.}
  \label{fig:forwarder}
\end{figure}

\subsubsection{A simple forwarder stream}

Suppose we would like to create a stream which simply publishes an event for
each event observed on another \verb|stream|. In this case, the constructs we
have seen so far are not sufficient, since an arbitrary number of events have
to be published from within the \verb|rasync| block. This is where the new
method \verb|yieldNext| comes in: it publishes the next event to the stream
returned by \verb|rasync|. Our simple forwarder example can then be expressed
as shown in Figure~\ref{fig:forwarder}.

Note that in the above example, the result of the body of the \verb|rasync|
block is \verb|None|; consequently, the resulting \verb|forwarder| stream only
publishes an \verb|onDone| event when \verb|rasync|'s body has been fully
evaluated. In this case, it is assumed that the only ``interesting'' non-done
events of \verb|forwarder| are published using \verb|yieldNext|.

\section{Translation}\label{sec:translation}

In this section we describe the translation of the introduced constructs.
Before considering the translation of \verb|rasync| blocks in combination with
methods like \verb|awaitNext|, we first give a short overview of the
translation of regular \verb|async| blocks as it is implemented in Scala
Async. As before, the exposition is driven by concrete code examples.

Consider the following simple use of \verb|async|/\verb|await|:

\begin{lstlisting}
val fut1: Future[T] = async {
  <expr1>
  val res = await(fut2)
  <expr2>
}
\end{lstlisting}

In general, \verb|async| blocks are translated into state
machines~\cite{ScalaAsyncSIP}. The above example is simple enough, though,
that we can illustrate how it maps to Scala's futures API without the
complexities associated with a state machine. For simplicity, we assume that
\verb|<expr2>| does not contain another invocation of \verb|await|. Then, the
above \verb|async| block can be translated, intuitively, as follows:

\begin{lstlisting}
val fut1: Future[T] = {
  val p = Promise[T]()
  future {
    <expr1>
    fut2 onComplete {
      case Success(res) => p.success(<expr2>)
      case Failure(t)   => p.failure(t)
    }
  }
  p.future
}
\end{lstlisting}

In the resulting program the body of the \verb|async { ... }| block is
contained within \verb|future { ... }| which asynchronously executes it on a
thread pool. Before starting this future, a new promise \verb|p| is created. A
promise is a placeholder for a result that becomes available asynchronously. A
promise can be resolved either with a successful result (using the
\verb|success| method) or with an exception (using the \verb|failure| method),
{\em at most once.} Each promise has a future associated with it which
provides a {\em read-only} interface to the asynchronous result. The future
associated with \verb|p| is the result of the original \verb|async| block.

One of the critical parts of the translation is the replacement of invocations
of \verb|await|. Instead of blocking the current thread until the awaited
future is completed, a completion callback is registered with the awaited
future. The completion callback is invoked when \verb|fut2| is completed; it
handles two cases for the successful (\verb|case Success(res)|) and the failed
(\verb|case Failure(t)|) completion of the future, respectively. In case of a
failure, promise \verb|p| is immediately completed with the exception \verb|t|
of the observed failure event. Otherwise, the rest of the \verb|async| block,
which in this case is just \verb|<expr2>|, is executed, and its result used to
complete \verb|p| successfully. Apart from the missing state machine logic
(which is not required in this simple case), this example translation does not
handle exceptions that are thrown within \verb|<expr2>|.

With this simplified overview of the translation of regular \verb|async|
blocks, we provide a sketch explaining the translation of \verb|rasync|
blocks.

\subsection{Reactive Async Translation}\label{sec:rasync-translation}

The translation of \verb|rasync| in combination with the \verb|await*| and
\verb|yield*| methods is very similar to the previous translation. The main
changes are the implementation of observables as the result of an
\verb|rasync| block, as well as the replacement of \verb|await*| invocations.

\begin{figure}[ht!]
  \centering
\lstset{numbers=left,xleftmargin=2em}
\begin{lstlisting}
val forwarder = {
  val ofp = ObservableFlowPool[T]()
  val sm  = new StateMachine {
    var state: Int = 0
    var next: Option[Int] = None
    var channels = Map[Observable, Channel[_]]()
    var subs = List[Closable]()
    def apply(): Unit = {
      val c = channels.get(stream) match {
        case None =>
          val channel = new Channel[Option[Int]]
          channels += (stream -> channel)
          subs ::= stream.subscribe(new Observer {
            def apply(tr: Try[Int]) = tr match {
              case Success(res) =>
                channel.put(Some(res))
              case Failure(t) =>
                ofp.failure(t)
            }
            def onDone() =
              channel.put(None)
          })
          channel

        case Some(c) =>
          c.asInstanceOf[Channel[Option[Int]]]
      }

      c get { res =>
        next = res
        state = if (res.isEmpty) 2 else 1
        resume()
      }
    }

    def resume(): Unit = state match {
      case 1 =>
        ofp << next.get
        apply()

      case 2 =>
        subs.foreach(c => c.close())
        ofp.done()
    }
  }

  future {
    sm.apply()
  }

  ofp.observable
}
\end{lstlisting}
  \caption{Result of reactive async translation.}
  \label{fig:rasync-translation}
\end{figure}

Consider the forwarder example from Figure~\ref{fig:forwarder}. Our extended
translation produces the program shown in Figure~\ref{fig:rasync-translation}
(simplified). The first interesting change is that instead of creating a
promise, an instance of \verb|ObservableFlowPool| is created. Like Scala's
promises, flowpools~\cite{ProkopecMSHO12} are a non-blocking data structure
which can be completed programmatically. Instead of carrying at most one
result, though, flowpools can carry an unbounded number of elements. Flowpools
are observable: callbacks can be registered which are called whenever a new
element is added to the flowpool. Moreover, it is possible to ``seal'' a
flowpool which means that no more elements can be added. This event, too, can
be observed; it plays the role of the \verb|onDone| event of reactive streams.
The observable associated with the flowpool is returned as the result of an
\verb|rasync| block (this is an extension of the original design
of~\cite{ProkopecMSHO12}).

For each observable that the \verb|rasync| block is awaiting events from, the
state machine maintains a non-blocking channel (in the \verb|channels| map). A
channel supports a non-blocking \verb|put| operation, as well as a non-
blocking \verb|get| operation. Each invocation of \verb|awaitNextOrDone| is
translated as follows. First, we check whether there is already a channel for
\verb|stream|. If not, we create a channel and subscribe an observer which puts
new events into the channel. Moreover, we call \verb|get| on the channel,
passing the current continuation. Whenever the channel receives the first
event the continuation is called, which executes the corresponding state of
the state machine. The continuation is (atomically) deregistered, so
that the following events are just enqueued in the channel. When the consumer
reaches the original \verb|awaitNextOrDone| invocation it gets either a queued
element from the channel, or, if the channel is empty, it registers its
continuation once again using \verb|get|. At the end of the \verb|rasync|
block, all collected subscriptions (\verb|subs|) are closed; this turns all
created channels into garbage.


\begin{figure}
  \centering
$\ba[t]{l@{\hspace{2mm}}l}
p    ::=  \seq{cd}~mb                                & \mbox{program}             \\
cd   ::=  \texttt{class}~C~\{\seq{fd}~\seq{md}\}     & \mbox{class declaration}   \\
fd   ::=  \texttt{var}~f: \sigma                     & \mbox{field}               \\
md   ::=                                             & \mbox{method declaration}  \\
\gap ~|~  \texttt{def}~m(\seq{x: \sigma}): \phi = mb & \mbox{sync method}         \\
\gap ~|~  \texttt{def}~m(\seq{x: \sigma}): \psi = \texttt{rasync}~\{~mb~\}  & \mbox{async method} \\
mb   ::=  \{~\seq{\texttt{var}~x: \sigma};\seq{e}~\} & \mbox{method body}         \\
\phi ::=  \sigma                                     & \mbox{return type}         \\
\sigma,\tau ::=                                      & \mbox{type}                \\
\gap ~|~  \gamma                                     & \gap\mbox{value type}      \\
\gap ~|~  \texttt{C}                                 & \gap\mbox{class type}      \\
                                                     & \gap\mbox{\em{(including a family}} \\
                                                     & \gap\mbox{\em{of types \texttt{Observable}$[\sigma]$)}} \\
\gamma ::=                                           & \mbox{value type} \\
\gap ~|~  \texttt{Boolean}                           & \gap\mbox{boolean}         \\
\gap ~|~  \texttt{Int}                               & \gap\mbox{integer}         \\
\psi ::= \texttt{Observable$[\sigma]$}               & \mbox{observable return type}    \\
\ea$
  \caption{Core language syntax. $C$ is a class name, $f,m$ are field and
    method names.}
  \label{fig:lang-syntax}
\end{figure}

\section{Formalization}

One of the contributions of this paper is a sketch of the operational semantics of the
proposed programming model. Our operational semantics generalizes the formal
model presented in~\cite{FormalizingAsync}. To make it easier to pinpoint the essential
semantic differences between our models, we will re-use their formal model.

\subsection{Syntax}

Figure~\ref{fig:lang-syntax} and Figure~\ref{fig:lang-syntax-2} show the
syntax of our core language. The core language is taken virtually unchanged
from~\cite{FormalizingAsync}. To make it more uniform with the rest of the
paper we use a Scala-like syntax, however. Like in the original paper, programs
are written in {\em statement normal form} (SNF) which forces all
subexpressions to be named; this simplifies the presentation of the
operational semantics. Note that our core language does not support any form
of subtyping, so class declarations do not specify a superclass. This is again
adopted from~\cite{FormalizingAsync}; the presented reactive features are
orthogonal to subtyping.

A RAY program consists of a collection of class definitions, as well as the
definition of a (\texttt{main}) method body. A class \texttt{C} has (a
possibly empty) sequence of  public fields and methods, $\seq{f}$ with types
$\sigma$, and $\seq{md}$, respectively. Importantly, method declarations may be
either synchronous, or asynchronous. In the synchronous case, methods are
public with return type $\phi$, a type which may represent either a class or
value type, and they may contain local variables and/or a list of expressions
$\seq{e}$. Asynchronous methods on the other hand are marked with
$\texttt{rasync}$ and are expected to have return type
\texttt{Observable$[\sigma]$}, but are otherwise syntactically the same
as synchronous methods.

The \texttt{Observable[$\sigma$]} family of types is used to model the
generic nature of observables. They represent observables such that an async
method can choose to await their next event using \texttt{awaitNextOrDone}.
Conversely, inside the body of an async method with result type
\texttt{Observable[$\sigma$]}, \texttt{yieldNext} can be used to publish an
event of type $\sigma$.

Expressions in RAY include constants, which can be either an integer $i$,
boolean $b$, or the \texttt{null} literal. They may also be represented by
class declarations, selections, invocations, or terms. Here, $x$ and $y$
represent variable names, while $f$ ranges over field names and $m$ ranges
over method names. In order to enforce the above-mentioned SNF, we include a
second syntactic category for terms.


\subsection{Operational Semantics}

\begin{figure}
  \centering
$\ba[t]{l@{\hspace{2mm}}l}
t    ::=  \texttt{let}~x = e~\mbox{in}~t                 & \gap\mbox{let binding}  \\
\gap ~|~ x.f = y                                         & \gap\mbox{assignment}   \\
\gap ~|~ \texttt{yieldNext}(x)                           & \gap\mbox{yield event}  \\
\gap ~|~ x                                               & \gap\mbox{variable}     \\
e    ::=                                                 & \mbox{expressions}      \\
\gap ~|~ \uline{b}                                       & \gap\mbox{boolean}      \\
\gap ~|~ \uline{i}                                       & \gap\mbox{integer}      \\
% \gap x \oplus y                                      & \gap\mbox{built-in operator}      \\
\gap ~|~ x                                               & \gap\mbox{variable}     \\
\gap ~|~ \texttt{null}                                        & \gap\mbox{null}          \\
\gap ~|~ x.f                                             & \gap\mbox{selection}    \\
\gap ~|~ x.m(\seq{y})                                    & \gap\mbox{invocation}   \\
\gap ~|~ \texttt{new C()}                                & \gap\mbox{instance creation}   \\
\gap ~|~ \texttt{awaitNextOrDone}(x)                     & \gap\mbox{await next event}   \\
\gap ~|~ t                                               & \gap\mbox{term}         \\
\ea$
  \caption{RAY expressions and terms.}
  \label{fig:lang-syntax-2}
\end{figure}

\begin{figure*}[ht!]
  \centering

\infrule[\textsc{E-RAsync-Yield}]
{  H_0(o) = \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\bar{F}, \bar{D}) \rangle \\
   \bar{R} = \{ \aframe {L_2[x \mapsto \texttt{Some}(L(z))]} {\bar{s_2}} {a(o_2)}~|~ \aframe {L_2} {\texttt{x = y.GetResult();} \bar{s_2}} {a(o_2)} \in \bar{F} \} \\
   \bar{N} = \{ \langle {o_2}, [] \rangle ~|~ \aframe {\_} {\_} {a(o_2)} \in \bar{R} \} \\
   \bar{D'} = \{ \langle {o_3}, \texttt{Some}(L(z)) :: q \rangle ~|~ \langle {o_3}, q \rangle \in \bar{D} \} \\
   H_1 = H_0[o \mapsto \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\epsilon, \bar{D'} \cup \bar{N}) \rangle]
}
{ \reducebreak {H_0} {\{ \aframe L {\texttt{yieldNext(z);} \bar{s}} {a(o)} \circ FS\} \cup P}
    {H_1} {\{ \aframe L {\bar{s}} {a(o)} \circ FS \} \cup \{ R \circ \epsilon ~|~ R \in \bar{R} \} \cup P}
}

\vspace{0.3cm}

\infrule[\textsc{E-RAsync-Return}]
{  H_0(o) = \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\bar{F}, \bar{D}) \rangle \\
   \bar{R} = \{ \aframe {L_2[x \mapsto \texttt{None}]} {\bar{s_2}} {a(o_2)}~|~ \aframe {L_2} {\texttt{x = y.GetResult();} \bar{s_2}} {a(o_2)} \in \bar{F} \} \\
   \bar{D'} = \{ \langle {o_3}, \texttt{None} :: q \rangle ~|~ \langle {o_3}, q \rangle \in \bar{D} \} \\
   H_1 = H_0[o \mapsto \langle \texttt{Observable$[\sigma]$}, state \mapsto done(\bar{D'}) \rangle]
}
{ \reducebreak {H_0} {\{ \aframe L {\epsilon} {a(o)} \circ FS\} \cup P}
    {H_1} {\{ FS \} \cup \{ R \circ \epsilon ~|~ R \in \bar{R} \} \cup P}
}

\vspace{0.3cm}

\infrule[\textsc{E-AwaitNextOrDone-1}]
{  L(y) = o_1 \\
   H_0(o_1) = \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\bar{F}, \bar{D}) \rangle \\
   \langle o, [] \rangle \in \bar{D} \lor \forall \langle {o_2}, q \rangle \in \bar{D}.~o_2 \neq o \\
   H_1 = H_0[o_1 \mapsto \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\aframe L {\texttt{x = y.GetResult();} \bar{s}} {a(o)} :: \bar{F}, \bar{D} \setminus \{ \langle o, [] \rangle \}) \rangle]
}
{ \fsreducebreak {H_0} {\aframe L {\texttt{x = awaitNextOrDone(y);} \bar{s}} {a(o)} \circ FS}
    {H_1} {FS}
}

\vspace{0.3cm}

\infrule[\textsc{E-AwaitNextOrDone-2}]
{  L(y) = o_1 \\
   H_0(o_1) = \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\bar{F}, \bar{D}) \rangle \\
   \bar{D} = \bar{D'} \cup \{ \langle o, q :: \texttt{Some}(e) \rangle \} \\
   H_1 = H_0[o_1 \mapsto \langle \texttt{Observable$[\sigma]$}, state \mapsto running(\bar{F}, \bar{D'} \cup \{ \langle o, q \rangle \}) \rangle]
}
{ \fsreducebreak {H_0} {\aframe L {\texttt{x = awaitNextOrDone(y);} \bar{s}} {a(o)} \circ FS}
    {H_1} {\aframe {L[x \mapsto e]} {\bar{s}} {a(o)} \circ FS}
}

  \caption{Transition rules for reactive async features.}
  \label{fig:opsem-rules}
\end{figure*}
% \vspace{-4em}

\subsubsection{Notation}

A heap, denoted $H$, partially maps object identifiers (ranged over by $o$) to
heap objects, denoted $\langle\texttt{C}, FM\rangle$, representing a pair of
type $\texttt{C}$ and a field map, $FM$. A field map partially maps fields $f$
to values (ranged over by $v$), where $v$ can be either an integer, a boolean,
\texttt{null}, or an object identifier (the address of an object in the heap).

Frames have the form $\aframe L {\bar{e}} l$ where $L$ maps local variables to
their values, $\bar{e}$ is a sequence of expressions, and $l$ is a label. A
label is either $s$ denoting a regular, synchronous frame, or $a(o)$ denoting
an asynchronous frame; in this case, $o$ is the heap address of a
corresponding observable object $\langle \texttt{Observable$[\sigma]$}, state \mapsto
running(\bar{F}, \bar{D}) \rangle$. $\bar{F}$ is a set of asynchronous frames,
namely, all observables that are currently suspended awaiting $o$ to publish a new
event. $\bar{D}$ is a set of so-called ``dormant queues'' which are explained
below. Invoking a synchronous method pushes a synchronous frame to the current
frame stack; invoking an asynchronous method pushes an asynchronous frame to
the current frame stack.

There are three kinds of transition rules. The first kind goes from a heap and
a frame to a new heap and a new frame (simple right arrow). The second kind
goes from a heap and a frame stack to a new heap and a new frame stack (double
right arrow). The third kind goes from a heap and a set of frame stacks to a
new heap and a new set of frame stacks (squiggly right arrow).

\subsubsection{Transition Rules}

Rule (E-RAsync-Yield) is an extended version of rule (E-Async-Return)
in~\cite{FormalizingAsync}. It shows how awaiters (frames $\bar{F}$) are
resumed when the current asynchronous frame yields a next event. An awaiter
has the form \newline $\aframe {L_2} {\texttt{x = y.GetResult();} \bar{s_2}} {a(o_2)}$.
The call $\texttt{y.GetResult()}$ is just a placeholder indicating that
the awaiter should be resumed with the next event that stream \verb|y| yields.
Note that the state of an observable is $running(\bar{F}, \bar{D})$ as opposed
to $running(\bar{F})$ in the simpler async case. The $\bar{D}$ are ``dormant''
queues, which are queues of awaiters that are currently not suspended, but
that might call \verb|awaitNextOrDone| again. To prevent these awaiters from
skipping events, we record them in this list of dormant queues, so that new
events can be queued up in the dormant queues, until \verb|awaitNextOrDone| is
called again. Another difference from the async formalization is that
\verb|GetResult| returns an option, which means upon yielding a next result,
the awaiter is resumed with value $\texttt{Some}(L(z))$.

Rule (E-RAsync-Return) applies when an asynchronous frame has been evaluated
to the end.

Rule (E-AwaitNextOrDone-1) only applies if in observable $o_1$ (the observable
of \verb|y|) there is no dormant queue for observable $o$ (the observable that
is waiting for the next event) or the dormant queue is empty. In the former
case, a new awaiter is created and added to observable $o_1$ in $H_1$. In the
latter case, the empty dormant queue is removed and a regular awaiter is added
to the awaiters of observable $o_1$.

Rule (E-AwaitNextOrDone-2) applies if the observable awaiting an event has a non-
empty dormant queue; in this case, the observable can continue while taking an
element out of the dormant queue.

\section{Related Work}

There is a large body of work investigating the relationship of events and
threads. Several proposals attempt to reconcile the flexibility and efficiency
of event-based programming with the simpler reasoning afforded by direct-
style, thread-based programming. Although similar in spirit, the present work
proposes an integration of two existing programming models: async/await in the
style of C\# and Reactive Extensions. Consequently, we refer to other recent
publications (e.g.,~\cite{FormalizingAsync}) for a discussion of events and
threads, and how they relate to the async/await model.

The implementation of our RAY model is related to Scala's CPS compiler
plugin~\cite{RompfMO09} which provides first-class delimited continuations.
However, there are important differences. Both Scala Async and RAY are
implemented using the macro system~\cite{burmako13} introduced in Scala 2.10,
which is a more lightweight approach compared to a compiler plugin. The
translation avoids a complex interaction with Scala's type checker; the
\verb|rasync|, \verb|await*|, and \verb|yield*| constructs are purely
syntactic instead of type-driven. The {\em Scala.React} programming
framework~\cite{MaierO13} builds on Scala's CPS plugin to avoid the inversion
of control inherent in the observer pattern. Like other FRP frameworks it
provides first-class time-varying signals which support the automatic
propagation of updates to other signals. This power comes at the cost of
support for concurrent signal propagation. In contrast, RAY is designed for
concurrency, but does not feature first-class signals.


\section{Conclusion}

This paper proposes RAY, a programming model and macro-based library for
Scala, which integrates the Async model of C\# and Scala with the Reactive
Extensions model. RAY supports both consuming and creating observable streams
in a familiar direct style, avoiding higher-order functions and low-level
callbacks in many cases. Moreover, it integrates Scala's widely-adopted
futures library into a unified programming model. Our goal with this
integration is to simplify reactive programming with Scala, async/await, and
reactive streams significantly.


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{bib}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
% \appendix


% \subsection{References}
% Generated by bibtex from your ~.bib file.  Run latex,
% then bibtex, then latex twice (to resolve references)
% to create the ~.bbl file.  Insert that ~.bbl file into
% the .tex source file and comment out
% the command \texttt{{\char'134}thebibliography}.
% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
% \balancecolumns
% That's all folks!
\end{document}
