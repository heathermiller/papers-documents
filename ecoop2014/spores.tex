% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{url}
\usepackage{todonotes}
\usepackage{listings}

\lstdefinelanguage{Scala}%
{morekeywords={abstract,case,catch,char,class,%
    def,else,extends,final,%
    if,import,%
    match,module,new,null,object,override,package,private,protected,%
    public,return,super,this,throw,trait,try,type,val,var,with,implicit,%
    macro,sealed,%
  },%
  sensitive,%
  morecomment=[l]//,%
  morecomment=[s]{/*}{*/},%
  morestring=[b]",%
  morestring=[b]',%
  showstringspaces=false%
}[keywords,comments,strings]%

\lstset{language=Scala,%
  mathescape=true,%
  columns=[c]fixed,%
  basewidth={0.5em, 0.40em},%
  basicstyle=\tt,%
  xleftmargin=0.0cm
}

%
\begin{document}
%
\mainmatter              % start of the contributions
%
\title{Spores: Function-Passing Style\todo{bad title}}
%
\titlerunning{Spores: Function-Passing Style}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Heather Miller\inst{1} \and Philipp Haller\inst{2}
\and Martin Odersky\inst{1}}
%
\authorrunning{Heather Miller et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Heather Miller, Philipp Haller, and Martin Odersky}
%
\institute{EPFL, Switzerland\\
\and
Typesafe, Switzerland}

\maketitle              % typeset the title of the contribution

\begin{abstract}

Functional programming is regularly touted as the way forward for bringing
parallel, concurrent, and distributed programming to the mainstream. The
popularity of the rationale behind this viewpoint (immutable data transformed
by function application) has even lead to a number of imperative and object-oriented (OO)
programming languages adopting building blocks such as lambdas
(functions)\todo{say something instead about closures}. For both functional 
and OO languages, however, distributing closures or using them in a concurrent 
environment remains challenging. This paper takes a
step towards more principled distributed and concurrent programming with functions we call
{\em function-passing style}\todo{should probably say something like "open
programming"}~by introducing a new closure-like abstraction and type system,
called {\em spores}, that can guarantee closures to be serializable, thread-safe, 
or even have custom user-defined properties. We present a model and type
system for expressing general type constraints and apply it to the problem of
guaranteeing serializability and thread-safety of closures. We implement our
approach as a module for Scala, and show the power of these guarantees through
a detailed case analysis of new distributed and concurrent frameworks that
this safe foundation for migratable closures enables.

\keywords{functions, closures, distributed programming, concurrent programming, type systems}
\end{abstract}
%
\section{Introduction}

With the growing trend towards cloud computing and mobile applications,
distributed programming has entered the mainstream. The traditional view of
software development as being focused on a program running on a single
machine, interacting directly with the user, has become largely obsolete.
Popular paradigms in software engineering such as software as a service
(SaaS), RESTful services, or the rise of multitudes of different models and
systems for big data processing and interactive analytics, evidence this
trend.
% From big data to paradigms like software as a service, RESTful blah, the . 
Whether we consider a cluster of commodity machines
churning through a massive data-parallel job, or a smartphone interacting with
a social network, all are ``distributed'' jobs, and all share the need to
interact in typically asynchronous, reactive ways with other clients or
services. \todo{make nod to functional futures, etc?} \todo{maybe make a nod to open programming?}

At the same time, the functional programming paradigm has irrefutably gained
traction in recent years, as is evidenced by the ongoing trend of
traditionally object-oriented or imperative languages being extended with
functional features, such as lambdas in Java~\cite{JavaLambdas},
C++~\cite{CplusplusLambas}, and \todo{add more}, as well as the increase in
use of functional languages on software repositories~\cite{find-something},
the perceived importance of functional programming in general empirical
studies on software developers~\cite{PLAdoption}\todo{check Leo's paper, add
others}, and the measurable popularity of functional programming massively
online open courses (MOOCs)~\cite{ICSEMOOC}.

Functions don't concern only functional programming languages anymore.

One reason \todo{make this less strong, or cite something}for the rise in
popularity of functional programming languages and features is the basic
philosophy of transforming immutable data via function application, and the
observation that this mode of reasoning about data in parallel, concurrent,
and distributed code is more tractable.

\todo{cite one or some of the lambda the ultimate papers here?}
\todo{need to cite a few papers that claim that FP is the way forward for parallel and distributed computing}

While purported to the way forward for bringing parallel, concurrent, and
distributed programming to the mainstream, functional programming languages
haven't yet taken off as the languages of choice for distributed and
concurrent programming in practice. For that, object-oriented languages with functional features such as Scala or Java take the lead. 

Java 8's streaming APIs focus on concurrency, expose functions to the user.
In Scala we have already gathered experience with these issues and thus we
believe they will apply to Java 8 as well

For both OO and functional languages, there still exist numerous hurdles at
the language-level for even these most basic functional building blocks to
overcome in order to be reliable and easy to reason about in concurrent or
distributed environments. For instance, a natural model for
functional languages to support is that of {\em moving functionality to
data}\todo{this is a really common idea, cite a bunch of stuff that aims for
this}. While a popular idea, there exist few distributed systems which embody
this approach, the most notable of which being Spark~\cite{Spark}, a fault-tolerant, 
in-memory distributed collections abstraction.

\todo{talk about issues of serializing lambdas in Java, Scala -- OO languages. Then discuss the problems of functional languages like Haskell too}

This paper takes a step towards more principled {\em function-passing
style}\todo{should probably say something like "open programming"}~by
introducing a new closure-like abstraction and type system that can guarantee
closures to be serializable, thread-safe, or even have user-defined
properties, called {\em spores}.

We first present a and then focus on an implementation of spores in Scala, a
hybrid object-oriented and functional programming language which faces the
issues brought by closures on all sides -- the issues encountered in
functional languages such as Haskell~\cite{CloudHaskell}, as well as issues
encountered by integrating closures with an object system, inheritance and
subtyping.

Need to talk about related work here.

% == NOTES ==
% We introduce a model for concurrent and distributed computing where the data is stationary and functions are mobile. This is a dual to the actor model, where functionality is stationary, and data is made mobile. 

% In theory you can migrate actors, in practice, you cannot. Can we use these insights to find a way to migrate actors cleanly?

% We describe a pattern for distributing lambdas in a principled way. We
% implement this pattern in the new spore-agent abstraction which enforces the
% rules of the pattern.

% We discuss problems in distributed programming that are simplified using the
% spore-agent abstraction compared to equivalent actor-based solutions.
% Moreover, we argue that spore-agents are dual to actors.

% Finally, we show that this spore-agent abstraction can be implemented
% efficiently; we show that our spore-agent implementation can outperform state-
% of-the-art actor frameworks on a set of applications where distributing
% lambdas is at the core.

% Distributed programming supposed to be made easier by going functional. But a problem of object-oriented languages with lambdas and functional programming languages alike is that functions can have free variables. Closures that close over some tricky environment. This means that regardless of the paradigm, framework designers can't confidently expose lambdas in APIs to users.

% Call on trend towards in-memory distributed computing.

% The design of our framework is guided by the following principles...

% In this paper, we present a model and type system for introducing general {\em type constraints}, and demonstrate its applicability 


\subsection{Problems of actors}

\begin{itemize}

\item Migrating actors is not supported in mainstream actor frameworks and
languages. For example, neither Akka nor Erlang support migrating actors from
one node to another.

\item Sending spores as messages to actors comes with the problem of matching
on the types of the spore which is not supported due to erasure in Scala.

\end{itemize}

We describe a pattern for distributing lambdas in a principled way. We
implement this pattern in a family of spore-agent abstractions which enforce
the rules of the pattern.

{\bf Motivations:}
\begin{itemize}
\item problems with distribution
\item problems with concurrency
\end{itemize}

\subsection{Contributions}

\begin{itemize}
\item we present a general model of \textit{spores}, functions that are guaranteed to be 
\item sdf
\end{itemize}

\subsection{Brainstorming}

Should focus on re-usable building blocks. Spores are re-usable by several
frameworks. What else is re-usable? A composition mechanism?

One thing could be to provide a mechanism to compose spores, but leave it open
how to execute that on a distributed middleware.

Make it easy to build an execution engine like the one from Spark.


This paper makes the following contributions:

\subsection{Jargon?}

Section on jargon. Lambdas, functions, closures. Introduce a baseline
vocabulary with respect to environment for duration of paper.

\subsection{Functions Across Languages}

A survey of the way different languages deal with functions and closures. How
the environment is kept, scoping, stack frames, etc.

Languages to compare with closures:

\begin{itemize}
\item Scala
\item Objective C
\item Java
\item VB.net
\item Python
\item Ruby
\item Javascript
\item Lisp
\item Perl
\item Lisp
\item Racket
\item Scheme
\item Clojure
\item Rust
\item Go
\item Dart
\item Haskell
\item ML
\item C++
\item Lua
\item Smalltalk
\item ECMAScript
\item C\# (Supports functions, but not closures. Emulates with delegates.)
\end{itemize}

\section{Lambda the Ultimate Distributive}

Lambdas provide a simple, principled way of handling the different kinds of
objects that are fundamental in distributed systems. This section describes a
pattern that we call ``Lambda the Ultimate Distributive'' for working with
lambdas in a distributed environment.

In a distributed system, different kinds of objects have to be handled in
different ways. Some of these objects are data that should be processed (like
a large collection), some of these objects represent services of the runtime
environment (e.g., for scheduling or communication).

Given the kind of object that is involved in a distributed computation, the
object has to be handled specially:
\begin{itemize}

\item (a) an object can be data that must be shipped between nodes to accomplish
some task;

\item (b) an object can be a runtime service, such as a scheduler, which is not
shippable, but must be used on each node;

\item (c) an object can be data which is not shippable for some reason, but might
have to be retrieved on multiple nodes.

\end{itemize}

The idea of ``lambda the ultimate distributive'' is that closures can handle
all of these kinds of objects in a principled and well-defined way (no
guessing needed):

\begin{itemize}

\item objects of kind (a) can be safely captured by the closure since they are shippable;

\item objects of kind (b) must be parameters of the closure; on each machine,
a reference the (local) runtime environment is passed as an argument to the
closure; (Individual services, like a scheduler, could be fields of a
wrapping ``environment'' object.)

\item objects of kind (c) must be parameters of the closure; on each machine,
they have to be retrieved first using an object of kind (b), and then passed
to the closure as an argument.

\end{itemize}

Using lambdas in this way allows modeling most situations \todo{make less vague}
in a distributed system in a principled way, without special tricks or
hacks. However, correctly using lambdas according to the above pattern
requires discipline, since properties such as serializability of captured
objects are typically not enforced by the language or type system.

\subsection{Limitations of simple lambdas}

Here we can point out problems of regular lambdas: accidentally capturing
references to enclosing objects, accidentally capturing non-serializable
objects, incorrect use of lambdas in concurrent code (one motivation for
parallel closures), accidentally accessing unstable members of captured
objects (important in particular in languages supporting the uniform access
principle like Eiffel [check], Smalltalk [check], and Scala).


\section{Spores: Closures with Constraints}

We would like to constrain the environment of a spore to express properties
such as:
\begin{itemize}
\item All captured objects must be serializable
\item All captured objects must be thread-safe
\item Captured objects must not be marked as unsafe for capturing
\end{itemize}
\noindent
Such properties restrict the types of objects that a spore is allowed to
capture. A naive way to achieve this would be to annotate certain types as
``not-safe-for-capturing''. However, this approach would be too inflexible,
since some desirable properties are orthogonal to others. For example, a
\verb|Promise| type~\cite{promise-paper} would be safe for capturing by a
spore used in a concurrent setting, whereas it would not be safe for capturing
by a spore that is intended to be serialized.

Thus, rather than permitting or disallowing types to be captured, in our
approach spores can express properties that the types of captured variables
are required to have. For example, a spore might require all captured types to
be thread-safe. Properties can also be composed, enabling spores to require
their captured types to have multiple properties. For example, in addition to
thread-safety, a spore may require its captured types to be serializable.
(Such a spore would be well-suited for computations that should be executed
concurrently on the same computer or on another computer depending on the
current work load.)

\subsection{The \texttt{Spore} trait}

To express type constraints we leverage two features of Scala's type system.
First, in Scala a function is an object of a type that extends one of the
predefined function traits. Thus, it is possible to subclass the predefined
function types. Second, in Scala classes and traits can be refined with value
and type members. As we will see, type members are a natural way to express
type constraints.

The type of single-argument spores is defined as follows:

\begin{lstlisting}
    trait Spore[-A, +R] extends Function1[A, R] {
      type Capture[T]
    }
\end{lstlisting}
\noindent
The \verb|Spore| trait extends the \verb|Function1| trait~\todo{variance annotations} which is defined as
follows in Scala's standard library:

\begin{lstlisting}
    trait Function1[-A, +R] extends AnyRef {
      def apply(v: A): R
      def andThen[B](g: R => B): A => B
      def compose[B](g: B => A): B => R
    }
\end{lstlisting}
\noindent
The above definition expresses the fact that functions are objects with an
\verb|apply| method; function composition is supported using the
\verb|andThen| and \verb|compose| methods.

The \verb|Capture[T]| type member of the \verb|Spore| trait is used to express
requirements of all captured types \verb|T| in the form of ``interfaces'' that
the captured types \verb|T| have to implement. As we will see below, instead
of using Java-style interfaces, we use a combination of traits and
implicits~\cite{Oliveira2010} akin to generalized interfaces in
JavaGI~\cite{WehrT11} or concepts in C++.

For example, a spore from \verb|Int| to \verb|String| that requires all
captured types to be serializable would have the following type:
\begin{lstlisting}
    Spore[Int, String] {
      type Capture[T] = Pickler[T]
    }
\end{lstlisting}
\noindent
The type member \verb|Capture[T]| is defined such that for each captured type
\verb|T| there must exist an instance of type \verb|Pickler[T]| (a ``pickler''
that can serialize or pickle objects of type \verb|T|). Such instances are
made available and looked up using Scala's {\em implicits} as shown below.

Just like requiring all captured types to have a certain property, sometimes
it's necessary to prevent types with a certain property from being captured.
While in principle this could be supported by requiring a property that's not
satisfied only by those types we wish to exclude from capturing, it would
require declaring all types that are not excluded, which would lead to a lot
of boilerplate. Instead, we introduce another type member \verb|NoCapture[T]|
used to express properties that lead to rejection of a captured type:\todo{also discuss subtypes}

\begin{lstlisting}
    trait Spore[-A, +R] extends Function1[A, R] {
      type Capture[T]
      type NoCapture[T]
    }
\end{lstlisting}
\noindent
Given this way of introducing constraints it's even possible to require
captured types to have multiple properties. Since properties are expressed
using traits, properties can be combined using mix-in composition. For
example, a spore requiring all captured types to be both serializable and
thread-safe would look as follows:

\begin{lstlisting}
    Spore[Int, String] {
      type Capture[T] = Pickler[T] with ThreadSafe[T]
    }
\end{lstlisting}
\noindent
The idea behind the property \verb|ThreadSafe| is that thread-safe types could
provide dummy implementations of the interface \verb|ThreadSafe[T]|. Moreover,
the \verb|with| keyword is used to create the mix-in composition of
\verb|Pickler[T]| and \verb|ThreadSafe[T]|. This composition is guaranteed to
be defined if we require all properties to be direct descendants of
\verb|AnyRef|, the top type of all reference types in Scala.

Spores without constraints have types of the following form:
\begin{lstlisting}
    Spore[A, R] {
      type Capture[T] = NoConstraint[T]
      type NoCapture[T] = NoConstraint[T]
    }
\end{lstlisting}

\subsection{Library-specific constraints}

One important goal of spores is to make the use of closure-based libraries
safer. This is enabled through subtyping: instead of using regular function
types, libraries can require the use of subtypes of the \verb|Spore| trait
introduced above.

For example, a concurrency library could declare certain types as not safe to
be captured by closures. We can express this using a type class, say,
\verb|Unsafe[T]|. For each type that should not be captured we introduce a
type class instance. For example, the following implicit object introduces an
instance of the \verb|Unsafe| type class for type \verb|Actor|:

\begin{lstlisting}
    implicit object unsafeActor extends Unsafe[Actor]
\end{lstlisting}
\noindent
To ensure that closures never capture types that are declared in such a way as
unsafe, the library could use the following type alias in place of the regular
type for functions of arity one:

\begin{lstlisting}
    type SafeSpore[A, R] = Spore[A, R] {
      type NoCapture[T] <: Unsafe[T]
    }
\end{lstlisting}
\noindent
The \verb|NoCapture| type member of the above \verb|Spore| subtype is refined
with the {\em upper type bound} \verb|Unsafe[T]|. This ensures that only spore
types whose \verb|NoCapture| type members mix in \verb|Unsafe| are compatible
(of course, they could be even more restrictive).

\subsection{Introducing custom constraints}

\subsection{Composing spores}


Type constraints for a newly defined spore can be introduced as follows:
\begin{lstlisting}
    spore {
      val s: String = // ...
      (p: Int) => {
        (1 to p).map(x => s).mkString("-")
      }
    }.with[Pickler]
\end{lstlisting}
\noindent

[explain how to exclude certain types]

[ideally safety properties of types can be declared retro-actively.]

[how do we motivate other, custom properties?]



\section{Function-Passing Paradigm}

Frameworks this new paradigm would enable. Relationship to NoSQL?

\subsection{General Model}

Goal of general model: to take this mess of closures and functions and trouble with environments that pains people across languages and propose an abstraction that gets rid of this confusion.

Include in the general model typing rules that makes this abstraction guaranteeably shippable
given some baseline simplified formalism.

\subsection{Meat}

Need to work out structure of this and an appropriate title for this section. Would include stuff like type system and type constraints for spores perhaps (or keep that in the general model section?). Composing spores with type constraints. Subtyping and type constraints.

\subsubsection{OO}

The question of -- I capture something of type MyActor
and the spore forbids capturing type Actor, and MyActor <: Actor
then what happens.

\section{Formalization}\label{sec:formal}

\subsection{Operational Semantics}\label{sec:opsem}

Goals:
\begin{itemize}
\item If an expression is type-correct, at runtime all its properties should be true. This is particularly 
  interesting for spore expressions.
\item Furthermore, whenever an expression is reduced the result of the reduction should also be type-correct which 
  makes sure it's static properties are preserved by reduction. (Preservation)
\item To achieve soundness of the type system, we would also like to show that if an expression in our core 
  language is type-correct, then the expression can be reduced. (Progress)
\end{itemize}

Spores are represented dynamically as tuples $(cs, is, fun)$ where cs is a
sequence of captured variables (the spore header), is is a sequence of type
class instances, and fun is the spore closure. The only free variables of the
spore closure are the variables in cs.

Creating spores:

\begin{lstlisting}
spore[P] {
  val x_1: T_1 = e_1
  ...
  val x_n: T_n = e_n
  (p: T) => body
}
\end{lstlisting}

A spore has properties $P_1, ..., P_m$ for its captured vars (for simplicity,
above there is only one property P). For now a property can be a type class
like Pickler or CanCapture.

Type classes could be supported as follows. During type checking, implicit
values could be looked up in the standard lexical scope but marked with the
implicit keyword. Type-checking could then rewrite the expression to one which
has the implicit values passed to the spore constructor.

We would rewrite the above expression to the following ($i_1, ..., i_n$ are type
class instances):

\begin{lstlisting}
createSpore[P] {
  val x_1: T_1 = i_1.capture(e_1)
  ...
  val x_n: T_n = i_n.capture(e_n)
  val is = List(i_1, ..., i_n)  // not sure, if we really need those
  (p: T) => body
}
\end{lstlisting}

We might not have to include lookup of implicit values in the formalization.
P[T] could simply return the instance of type class P for type T.

We just need to store those type class instances in the dynamic representation
of spores, so that we have access to them dynamically (since we need to
evaluate the calls to capture).

\subsubsection{Reduction rules}

Reducing spore creation. Spore creation evaluates the spore header which
evaluates the captured expressions $e_1, ..., e_n$, and then passes the results
through the capture methods of the type class instances. The end result is a
sequence of references that we're going to store in the spore tuple (the cs).

Reducing spore application. An application e1 e2 of a spore e1 to an argument
e2 can be reduced by first reducing e1 until it's a reference r1. Then, we
look up the tuple (cs, is, fun) in the heap that reference r1 maps to. Then,
when e2 has also been reduced to a reference r2, we can replace r1 r2 by fun
such that all free vars are replaced by cs and the parameter is replaced by
r2.

\subsubsection{Dynamic representation of spores}

For preservation we then also need to show that $r1$ has the same type as the
\verb|spore| expression. Basically, we need enough dynamic information, so
that we can assign the following type to $r1$:

\begin{lstlisting}
Spore[A, B] {
  type All = P
  type Include = Capture[List[Int]]
  type Exclude = NoCapture[Actor] with NoCapture[Socket]
}
\end{lstlisting}

That means in the opsem, instead of the simple tuple $(cs, is, fun)$ we need to
have a tuple such as
$([{P} ; {List[Int]} ; {Actor, Socket}] A \Rightarrow B, cs, is, fun)$.

Examples for classes that are thread-safe but not shippable: Future/Promise,
Scheduler, ExecutorService, SparkContext (TODO: check). So, we might want to
permit those classes in some spores (those that are not shipped but might be
shared between threads), but not in other spores (those that are shipped).
That's why globally disallowing a type from being captured is not a good idea
and per-spore constraints are better.


\section{Implementation}

Comparison and relationship with Java8 SAM stuff.

\section{Use-Cases?}

We could show in an example-driven (or even paradigm-driven) way how the
active objects pattern can be implemented on top of spores. And then we can
show how spores help enforce certain safety properties that are important for
that pattern. For example, in the active objects pattern it's important to
either capture only immutable things, or clone things upon capturing.

Paradigms or patterns built on top of spores:

\begin{itemize}
\item Distributed collections like Spark
\item Active objects
\item Futures
\item Hot-swapping actors
\item Distributed pipelines / distributed streams
\end{itemize}

\section{Implementation}

\section{Evaluation}

% program    | LOC | #closures | #converted | LOC changed | #captured vars
%
% funsets    |  99 | 8 + (1)   | 8          | 7           | 9
% forcomp    | 201 | 6 + (2)   | 4          | 4           | 0
% mandelbrot | 325 | 1         | 1          | 9           | 4
% barneshut  | 722 | ??        | ??         | ??          | ??
% pagerank   | ??  | ??        | ??         | ??          | ??

\section{Related Work}

Non-academic related work: functions in Rust, 3 different types based on
different possibilities for environments \cite{RustFunctions}; functions,
closures, and procedures. Procedures are shippable.

Parallel closures \cite{ParallelClosures}. First known example of closures
with effectively immutable environment.

CloudHaskell \cite{CloudHaskell}. Introduces a type system that rejects anything
that is not static. Too strict.

C++ 11 comes with a capture syntax. Though, it's not possible to guarantee that construction is correct. If you require certain things from the closure, how is it expressed? If a method declares a parameter type which is a closure, the important thing is that in this parameter type, you can specify the requirements about capturing. So it's ensured that whatever's passed as an argument to the method satisfies these requirements. This isn't possible with C++ 11 closures. \cite{Cplusplus11Spec}

Active objects also related. \cite{ActiveObjects}

Clojure comes with the notion of an agent~\cite{Clojure} which is similar to our synchronization mechanism in that in the Clojure model, functions are sent to other agents which manage some sort of mutable, shared state. The spores-agent model focuses on more than managing mutable state. No notion of shippability, fully-focused on multicore single-machine scenario.

\bibliographystyle{abbrv}
\bibliography{bib}

\end{document}
