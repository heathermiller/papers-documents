%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint,10pt]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
% \usepackage{color}
\usepackage{listings,xspace}
\usepackage{amsthm}
\usepackage{mdframed}
\usepackage{xcolor}
\usepackage{fontspec}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{wasysym}

\lstdefinelanguage{Scala}%
{morekeywords={abstract,case,catch,char,class,%
    def,else,extends,final,%
    if,import,%
    match,module,new,null,object,override,package,private,protected,%
    public,return,super,this,throw,trait,try,type,val,var,with,implicit,%
  },%
  sensitive,%
  morecomment=[l]//,%
  morecomment=[s]{/*}{*/},%
  morestring=[b]",%
  morestring=[b]',%
  showstringspaces=false%
}[keywords,comments,strings]%

\lstset{language=Scala,%
  mathescape=true,%
  columns=[c]fixed,%
  basewidth={0.5em, 0.40em},%
  basicstyle=\tt,%
  xleftmargin=0.0cm
}

\makeatletter
\def \@ivtitleauthors#1#2#3#4{%
  \if \@andp{\@emptyargp{#2}}{\@emptyargp{#3}}%
    \noindent \@setauthor{40pc}{#1}{\@false}\par
  \else\if \@emptyargp{#3}%
    \noindent \@setauthor{17pc}{#1}{\@false}\hspace{3pc}%
              \@setauthor{17pc}{#2}{\@false}\par
  \else\if \@emptyargp{#4}%
    \noindent \@setauthor{17pc}{#1}{\@false}\hspace{3pc}%
              \@setauthor{17pc}{#3}{\@false}\par
  \else
    \noindent \@setauthor{9.3333pc}{#1}{\@false}\hspace{1.5pc}%
              \@setauthor{9.3333pc}{#2}{\@false}\hspace{1.5pc}%
              \@setauthor{9.3333pc}{#3}{\@false}\hspace{1.5pc}%
              \@setauthor{9.3333pc}{#4}{\@true}\par
    \relax
  \fi\fi\fi
  \vspace{20pt}}
\def \@maketitle {%
  \begin{center}
  \@settitlebanner
  \let \thanks = \titlenote
  {\leftskip = 0pt plus 0.25\linewidth
   \rightskip = 0pt plus 0.25 \linewidth
   \parfillskip = 0pt
   \spaceskip = .7em
   \noindent \LARGE \bfseries \@titletext \par}
  \vskip 6pt
  \noindent \Large \@subtitletext \par
  \vskip 12pt
  \ifcase \@authorcount
    \@latex@error{No authors were specified for this paper}{}\or
    \@titleauthors{i}{}{}\or
    \@titleauthors{i}{ii}{}\or
    \@titleauthors{i}{ii}{iii}\or
    \@ivtitleauthors{i}{ii}{iii}{iv}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\@titleauthors{x}{}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\@titleauthors{x}{xi}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\@titleauthors{x}{xi}{xii}%
  \else
    \@latex@error{Cannot handle more than 12 authors}{}%
  \fi
  \vspace{1.75pc}
  \end{center}}
\makeatother

\theoremstyle{definition}
\newmdtheoremenv[hidealllines=true,topline=true,bottomline=true,skipabove=\baselineskip,skipbelow=\baselineskip]{defn}{Definition}[section]

\theoremstyle{definition}
\newmdtheoremenv[hidealllines=true,topline=true,bottomline=true,skipabove=\baselineskip,skipbelow=\baselineskip]{prop}{Property}[section]

% \newtheorem{defn}{Definition}[section]
% \newenvironment{defn}
  % {\begin{mdframed}[style=warning]\begin{mdef}}
  % {\end{mdef}\end{mdframed}}

\newcommand{\todo}{{\bf \colorbox{red}{\color{white}TODO:}}}
\newcommand{\ie}{{\em i.e.,~}}
\newcommand{\eg}{{\em e.g.,~}}
\newcommand{\term}[1]{\mbox{\texttt{#1}}}
\newcommand{\itl}[1]{\mbox{\textit{#1}}}

\begin{document}

\setmainfont[Mapping=tex-text]{Times New Roman}
\setmonofont[Scale=0.8,BoldFont={Consolas Bold}]{Consolas}

\conferenceinfo{OOPSLA '13}{October 26-31, Indianapolis, IN, USA.}
\copyrightyear{2013}
\copyrightdata{[to be supplied]}

% \titlebanner{banner above paper title}        % These are ignored unless
% \preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Object-Oriented Pickler Combinators}
\subtitle{and an Extensible Generation Framework}

\authorinfo{Heather Miller}
           {EPFL, Switzerland}
           {heather.miller@epfl.ch}
\authorinfo{Philipp Haller}
           {Typesafe, Switzerland}
           {philipp.haller@typesafe.com}
\authorinfo{Eugene Burmako}
           {EPFL, Switzerland}
           {eugene.burmako@epfl.ch}
\authorinfo{Martin Odersky}
           {EPFL, Switzerland}
           {martin.odersky@epfl.ch}

\maketitle

\begin{abstract}

Serialization or pickling, i.e., persisting runtime objects by converting them
into a binary or text representation is ubiquitous in distributed programming.
Pickler combinators are a popular approach from functional programming designed to
alleviate some of the tedium of writing pickling code by hand, but they don't
translate well to object-oriented programming due to qualities like open class
hierarchies and ad-hoc polymorphism. Furthermore, both functional pickler
combinators and Java-based serialization frameworks tend to be tied to a
specific pickle format, leaving programmers no choice of how their data is
persisted. In this paper, we present object-oriented pickler combinators and a
framework for generating them at compile-time, designed to be the default
serialization mechanism of the Scala programming language. Our framework is
extensible; (1) using Scala's implicit parameters, users can add their own
easily-swappable pickle format, (2) using the type class pattern, users can
provide their own custom picklers to override the default behavior of the
Scala pickling framework. In addition to extensibility and need for little to
no boilerplate, the static generation of our OO picklers achieves an order of
magnitude speedup over Java Serialization and up to a factor 7 speedup over
popular ``fast'' Java serialization frameworks like Kryo.
\todo mention Akka \& Spark?
% We go on to evaluate
% our framework on two large industrial-strength frameworks for distributed
% computing, Akka and Spark, and show improved performance and a reduction of
% lines of serialization-related code for both projects.

\end{abstract}

\category{D.3.2}{Programming Languages}{Language Classifications --
  multiparadigm languages, object-oriented languages, applicative
  (functional) languages}
\category{D.3.3}{Programming Languages}{Language Constructs and
  Features -- input/output}

% \terms
% term1, term2

\keywords
Serialization, pickling, meta-programming, distributed programming, Scala

\section{Introduction}

With the growing trend towards cloud computing and mobile applications,
distributed programming has entered the mainstream. As more and more
traditional applications migrate to the cloud, the demand for interop between
different services is at an all-time high, and is increasing. At the center of
it all is communication. Whether we consider a cluster of commodity machines
churning through a massive data-parallel job, or a smartphone interacting with
a social network, all are ``distributed'' jobs, and all share the need to
communicate in various ways, in many formats, even within the same
application.

A central aspect to this communication that has received suprisingly little
attention in the literature is the need to serialize, or {\em pickle} objects
{\em i.e.,} to persist in-memory data by converting them to a binary, text, or
some other representation. On the JVM, serialization has long been
acknowledged as having a high overhead \cite{Welsh2000, Carpenter1999}, with
some estimates purporting object serialization to account for 25-65\% of the
cost of remote method invocation, and which go on to observe that the cost of
serialization grows with growing object structures up to 50\%
\cite{Philippsen2000, Maassen1999}.

Due to the prohibitive cost of using Java Serialization in high-performance
distributed applications, many frameworks for distributed computing, like
Akka~\cite{Akka}, Spark~\cite{Zaharia2012}, SCADS \cite{Armbrust2009}, and
others, provide support for higher-performance alternative frameworks such as
Google's Protobuf~\cite{Protobuf}, Apache Avro~\cite{Avro}, or
Kryo~\cite{Kryo}. However, the higher efficiency typically comes at the cost
of weaker or no type safety, a fixed serialization format, more restrictions
placed on the objects to-be-serialized, or only rudimentary language
integration.

This paper takes a step towards more principled open programming through a new
foundation for pickling in object-oriented languages. We present object-oriented
picklers and a framework for generation either at runtime or at
compile time. The introduced notion of object-oriented pickler combinators
extends pickler combinators known from functional
programming~\cite{Kennedy2004} with support for object-oriented concepts such
as subtyping and mix-in composition. In contrast to pure functional-style
pickler combinators, we employ static, type-based meta programming to compose
picklers at compile time. The resulting picklers are efficient, since the
pickling code is generated statically as much as possible, avoiding the
overhead of runtime reflection~\cite{Gil2008,Dubochet2011}.

What's more, the presented pickling framework is extensible in several
important ways. First, building on an object-oriented type-class-like
mechanism~\cite{Oliveira2010}, our approach enables retroactively adding
pickling support to existing, unmodified types. Second, our framework provides
pluggable pickle formats which decouple type checking and pickler composition
from the lower-level aspects of data formatting. This means that the type
safety guarantees provided by type-specialized picklers are ``portable'' in
the sense that they carry over to different pickle formats.

The design of our framework has been guided by the following principles:
\begin{itemize}
\item {\bf Ease of use}. The programming interface aims to require as little
pickling boilerplate as possible. Thanks to dedicated support by the
underlying virtual machine, Java's serialization~\cite{JavaSerialization}
requires only little boilerplate, which mainstream Java developers have come
to expect. Our framework aims to be useable in production environments, and
must, therefore, be able to integrate with existing systems with minimal
changes.

\item {\bf Performance}. The generated picklers should be efficient enough  so
as to enable their use in high-performance distributed, ``big data'', and
cloud applications. One factor driving practitioners away from Java's default
serialization mechanism is its high runtime overhead compared to alternatives
such as Kryo, Google's protocol buffers or Apache's Avro serialization
framework. However, frameworks such as the latter offer only minimal language
integration.

\item {\bf Extensibility}. It should be possible to add pickling support to existing
types retroactively. This resolves a common issue in Java-style serialization
frameworks where classes have to be marked as serializable upfront,
complicating unanticipated change. Furthermore, type-class-like extensibility
enables pickling also for types provided by the underlying runtime environment
(including built-in types), or types of 3rd party libraries.

\item {\bf Pluggable Pickle Formats}. It should be possible to easily swap target
pickle formats, or for users to provide their own customized format. It is not
uncommon for a distributed application to require multiple formats for
exchanging data, for example an efficient binary format for exchanging system
messages, or JSON format for publishing feeds. Type-class-like extensibility
makes it possible for users to define their own pickle format, and to easily
{\em swap it in} at the use-site.

\item {\bf Type safety}. Picklers should be type safe through (a) type
specialization and (b) dynamic type checks when unpickling to transition
unpickled objects into the statically-typed ``world'' at a well-defined program
point.

\item {\bf Robust support for object-orientation}. Concepts such as subtyping and
mix-in composition are used very commonly to define regular object types in
object-oriented languages. Since our framework does without a separate data
type description language ({\em e.g.,} a schema), it is important that regular
type definitions are sufficient to describe the types to-be-pickled. The
Liskov substitution principle is used as a guidance surrounding the
substitutability of both objects to-be-pickled and first-class picklers.
\end{itemize}


\subsection{Related Work}

Some OO languages like Java and runtime environments like the JVM or .NET
provide serialization for arbitrary types, provided entirely by the underlying virtual
machine. While this approach is very convenient for the programmer there are
also several issues: (a) the pickling format cannot be exchanged (Java), (b)
serialization relies on runtime reflection which hits performance, and (c)
existing classes that do not extend a special marker interface are not
serializable, which often causes oversights resulting in software engineering
costs. In functional languages, pickler combinators can reduce the
effort of manually writing pickling and unpickling functions to a large
extent. However, existing approaches do not support object-oriented concepts
such as ad-hoc polymorphism. Moreover, it is not clear whether local type
inference as required in OO languages would yield a comparable degree of
conciseness, acceptable to programmers used to Java-style serialization.
Nonetheless, our approach builds on pickler combinators, capitalizing on their superior
composability. We discuss further, less-closely related work in Section
\ref{sec:related-work}.

\subsection{Contributions}

This paper makes the following contributions:

\begin{itemize}

\item An extension to pickler combinators, well-known in functional
programming, to support the core concepts of object-oriented programming,
namely ad-hoc polymorphism and open class hierarchies.

\item A framework based on object-oriented pickler combinators which (a)
enables retrofitting existing types with pickling support, (b) supports
automatically generating picklers at compile time and at runtime, (c) supports
pluggable pickle formats, and (d) does not require changes to the host
language or the underlying virtual machine.

\item A complete implementation of the presented approach in and for Scala \footnote{See
    \texttt{http://github.com/heathermiller/scala-pickling/}}.

\item An experimental evaluation comparing the performance of our framework
with Java serialization and Kryo. In microbenchmarks our framework outperforms
Java serialization by a factor of X and Kryo by a factor of Y. We also
evaluate the performance on a set of data types used in large industrial-strength
distributed computing frameworks and applications, and show an
integration in Spark and Akka.

\end{itemize}

\section{Background}
\label{sec:background}

The design and implementation of our pickling framework leverages
several advanced features of the Scala programming language. This
section introduces everything that is required to understand the rest
of the paper. Apart from this section the reader is expected to be
familiar with a typical statically-typed, class-based object-oriented
programming language such as Java or C\#.

\subsection{Implicits}
\label{sec:implicits}

\paragraph{Implicit Parameters.} In Scala, it is possible to select values
automatically based on type. These capabilities are enabled when using the
\term{implicit} keyword. For example, a method \term{log} with multiple
parameter lists may annotate their last parameter list using the
\term{implicit} keyword.

\begin{lstlisting}
def log(msg: String)(implicit o: PrintStream) =
  o.println(msg)
\end{lstlisting}

This means that in an invocation of \term{log}, the implicit argument list may
be omitted if, for each parameter of that list, there is exactly one value of
the right type in the {\em implicit scope}. The implicit scope is an
adaptation of the regular variable scope; imported implicits, or implicits
declared in an enclosing scope are contained in the implicit scope of a method
invocation.

\begin{lstlisting}
    implicit val out = System.out
    log("Does not compute!")
\end{lstlisting}

In the above example, the implicit val \term{out} is in the implicit scope of
the invocation of \term{log}; since it has the right type, it is automatically
selected as an implicit argument.

\todo Maybe we should change this example? It's out of Bruno's paper, and he's
on the committee, he'll probably review our paper.

\todo Talk about how we use implicit values in our framework here.

\paragraph{Implicit Conversions.} Implicit conversions can be thought of as
methods which, like implicit parameters, can be implicitly selected (\ie
invoked) based upon their type, and whether or not they are present in
implicit scope. As with implicit parameters, implicit conversions also carry
the \term{implicit} keyword before their declaration.

\begin{lstlisting}
 implicit def intWrapper(x: Int): Message =
    new Message {
      def message: String = "secret message!"
    }
\end{lstlisting}

In the example above, assuming there exists an abstract class \term{Message}
with abstract method \term{message}, the implicit conversion
\term{intWrapper} will be triggered when a method called \term{message}
is called on an \term{Int}. That is, simply calling
\term{39.message} will result in ``secret message!'' being returned.

\todo Talk about how we use implicit conversions in our framework here.

% cite Adriaan's and Bruno's OOPSLA paper. Where? How?
% Example of a type class: maybe Ordering type class of std lib?
% Include info on importing implicit values, and implicit resolution by scoping.
% Example of a plain implicit parameter: could use implicit ExecutionContext in futures

\subsection{Reflection}
\label{sec:reflection}

Reflection is the ability of a program to inspect, and possibly even modify
itself at runtime. Before Scala 2.10, Scala did not have any reflection
capabilities of its own. Instead, one could use Java reflection which provided
a very limited subset of runtime reflection capabilities. In Scala 2.10, a new
reflection library was introduced not only to address the shortcomings of
Java's runtime reflection on Scala-specific and generic types, but to also add
a more powerful toolbox of general reflective capabilities to Scala. Along
with full-featured runtime reflection for Scala types and generics, Scala 2.10
also ships with compile-time reflection capabilities, in the form of macros
(covered in Section \ref{sec:macros}), as well as the ability to reify Scala
expressions into abstract syntax trees.

\paragraph{TypeTags.} One aspect of runtime reflection that was introduced in
Scala 2.10 is the notion of \verb|TypeTag|s. As with other JVM languages,
Scala's types are erased at compile time. \verb|TypeTag|s can be thought of as
objects which carry along all type information available at compile time, to
runtime. As we will see, \verb|TypeTag|s will prove to be invaluable in
situations where precise type information would otherwise not be available at runtime.

\paragraph{Unified Runtime/Compile-time Reflection API.} Another important
aspect of Scala's reflection library is the one-to-one correspondence between
Scala Reflection's compile-time (\ie macros) and runtime APIs. Each API is
parameterized on a so-called \verb|Universe|, an object which serves as the
entry point to Scala reflection, and which provides all principal concepts
used in reflection, such as \verb|Type|s, \verb|Tree|s, and
\verb|Annotation|s. Depending on the task at hand, the choice between runtime
and compile-time reflection is as easy as selecting either a compile-time or a
runtime \verb|Universe|. As we will see, this enables maximum code
reuse in that a fallback runtime pickler generation mechanism can be achieved
by simply reusing the code for static generation, and parameterizing it on a
runtime \verb|Universe|.


\subsection{Macros}
\label{sec:macros}

Scala reflection enables a form of metaprogramming which makes it possible for
programs to modify themselves at compile-time. This compile-time reflection is
realized in the form of hygenic macros \cite{Burmako2012}, which {\em expand}
at compile-time to manipulate abstract syntax trees (ASTs). In our framework, we make
use of two principal types of macros.

\paragraph{Macro defs.} Macro defs are methods that are transparently loaded
by the compiler and executed (or expanded) during compilation. A macro is
defined as if it is a normal method, but it is linked using the \verb|macro|
keyword to an additional method that operates on abstract syntax trees.

\begin{lstlisting}
def assert(x: Boolean, msg: String): Unit =
  macro assert_impl
def assert_impl(c: Context)
  (x: c.Expr[Boolean], msg: c.Expr[String]):
                            c.Expr[Unit] = ...
\end{lstlisting}

In the above, the parameters of \verb|assert_impl| are syntax
trees, which the body of \verb|assert_impl| will operate on, itself returning
an AST of type \verb|Expr[Unit]|. It is \verb|assert_impl| which is
expanded and evaluated at compile-time, its result is then inlined at the
callsite of \verb|assert| and the inlined result is typechecked
It is also important to note that implicit defs as described earlier
in Section \ref{sec:implicits} can be implemented as macros.

As we will see, these macros defs, coupled with implicits in Scala enable the
boilerplate-free usage of the Scala pickling framework at the pickling use-
site.

\paragraph{Macro Annotations.} Unlike macro defs, macro annotations are capable
of {\em adding members} to classes which carry their annotation.

\begin{lstlisting}
@withNewToString
class D { ... }
\end{lstlisting}

The \verb|withNewToString| annotation is defined using a standard class
definition by extending a special \verb|MacroAnnotation| marker trait, and by
implementing a special \verb|transform| method as a macro:

\begin{lstlisting}
class withNewToString extends MacroAnnotation {
  def transform = macro transform_impl
  def transform_impl = { ... }
}
\end{lstlisting}

The \verb|transform| macro implementation is passed the AST of the annotated class
definition (the AST of ``\verb|class D { ... }|''), and returns a possibly changed AST
as the new class definition (which could have added members, changed
constructor parameters etc.)

\section{Overview and Usage}
\label{sec:overview}

\subsection{Basic Usage}

The Scala Pickling framework was designed so as to require as little
boilerplate from the programmer as possible. For that reason, pickling or
unpickling an object \term{obj} of type \term{Obj} requires simply,

\begin{lstlisting}
import scala.pickling._
val pickl = obj.pickle
val obj2 = pickl.unpickle[Obj]
\end{lstlisting}

Here, the \term{import} statement imports the Scala Pickling framework
the method \term{pickle} triggers static pickler generation, and the
method \term{unpickle} triggers static unpickler generation. Note that not
every type has a \term{pickle} method; it is implemented as an extension
method using implicits (Section \ref{sec:implicits}), imported into scope as a
member of the \term{scala.pickling} package.

Optionally, a user can
import a \term{PickleFormat}. By default, our framework provides a
Scala Binary Format, an efficient representation based on arrays of bytes,
though the framework provides other formats which can easily be imported,
including a JSON format. Furthermore, users can easily extend the framework by
providing their own \term{PickleFormat}s (See Section \ref{sec:pickleformat}).

Typically, the framework generates the required pickler itself inline in the
compiled code, using the \term{PickleFormat} in scope. In the case of JSON,
for example, this amounts to the generation of string concatenation code and
field accessors for getting runtime values, all of which is inlined, resulting
in high performance (see Section~\ref{sec:evaluation}).

In rare cases, however, it is necessary to fall back to runtime picklers which
use runtime reflection to access the state that is being pickled and
unpickled. For example, a runtime pickler is used when pickling instances of a
generic subclass of the static class type to-be-pickled.

Note that in the above example, the \term{unpickle} method is parameterized on
\term{obj}'s precise type \term{Obj}. Using the Scala Pickling framework, it's
also possible to pickle and unpickle subtypes, even if the pickle and unpickle
methods are called using supertypes of the type to-be-pickled.
For example,

\begin{lstlisting}
class Person(val name: String)
class Firefighter(val name: String, val since: Int)
  extends Person(name)

val ff = new Firefighter("Jim", 2005)
val pickl = ff.pickle[Person]
val ff2 = pickl.unpickle[Person]
\end{lstlisting}

In the above example, the runtime type of \term{ff2} will correctly be
\term{Firefighter}.

This perhaps raises an important concern-- what if the type that is passed as
a type argument to method \term{unpickle} is incorrect? In this case, the
framework will fail with a runtime exception at the call-site of
\term{unpickle}. This is an improvement over other frameworks, which have less
type information available at runtime, resulting in wrongly unpickled objects
often propagating to other areas of the program before an exception is thrown.

The Scala Pickling framework is also able to unpickle values of static type
\term{Any}. Scala's pattern-matching syntax can make unpickling on less-specific
types quite convenient, for example:

\begin{lstlisting}
val unpickld = pickl.unpickle[Any] match {
  case Firefighter(name, since) => ...
  case x: Int => ...
  ...
}
\end{lstlisting}

Beyond dealing with subtypes, our pickling framework supports
pickling/unpickling most Scala types, including generics, case classes, and
singleton objects. Passing a type argument to pickle, whether inferred or
explicit, which is an unsupported type leads to a compile-time error. This
avoids a common problem in Java-style serialization where non-serializable
types are only discovered at runtime, in general. Function types, however, are
not yet supported, and are planned future work.

\subsection{Advanced Usage}
\label{sec:pickleable-annotation}

\paragraph{$@$pickleable Annotation.} To handle subtyping correctly, the
pickling framework generates dispatch code which delegates to a pickler
specialized for the runtime type of the object to-be-pickled, or, if the
runtime type is unknown, which is to be expected in the presence of separate
compilation, to a generic, but slower, runtime pickler.

For higher performance, the Scala Pickling framework additionally provides an
annotation which at compile-time inserts a runtime type test to check whether
the runtime class extends a certain class/trait; in which case, we call the
method that returns the pickler specialized for that runtime class. If the
class/trait has been annotated, the returned pickler has been generated
statically (when the annotation, implemented using a macro, is expanded in
each subclass, transitively).

This \term{$@$pickelable} annotation enables:

\begin{itemize}
\item library authors to guarantee to their clients that picklers for separately-compiled
subclasses are fully generated at compile-time.

\item faster picklers in general because one need not worry about having to
fallback on a runtime pickler.
\end{itemize}

\paragraph{Custom Picklers.} It is possible to use manually-written picklers
in place of generated picklers. Typical motivations for doing so are (a)
improved performance through specialization and optimization hints (discussed
in Section~\ref{sec:optimize}), and (b) custom pre-pickling and post-unpickling
actions; such actions may be required to re-initialize an object
correctly after unpickling. Creating custom picklers is greatly facilitated by
modular composition using object-oriented pickler combinators. The design of
these first-class object-oriented picklers and pickler combinators is
discussed in detail in the following Section~\ref{sec:oopicklers}.


\section{Model of Object-Oriented Picklers}
\label{sec:oopicklers}

In this section we provide a formal definition of object-oriented picklers. We
introduce picklers as first-class objects, and provide their type definitions
and contracts that valid implementations must guarantee. Subsequently, we
demonstrate that the introduced picklers enable modular, object-oriented
pickler combinators, \ie methods for composing more complex picklers from
simpler primitive picklers.

Note that we are using a Scala-like program notation. However, the introduced
concepts and definitions are realizable in most statically-typed OO languages
with generics.

\begin{defn}(First-Class Picklers and Unpicklers)

A pickler for some type $T$ is an instance of one of two abstract class or
interface types \term{DPickler}$[T]$ or \term{SPickler}$[T]$. Each have an
abstract method \verb|pickle| with a single parameter of type $T$ and return
type \term{Pickle}:

\begin{lstlisting}
    trait DPickler[T] {
      def pickle(obj: T): Pickle
    }
\end{lstlisting}

\noindent(The type definition of \term{SPickler}$[T]$ differs only in the name of the type;
below we define the difference in their contracts.)

Conversely, an unpickler for some type $U$ is an instance of an abstract class
or interface type \term{Unpickler}$[U]$ that has a single abstract method
\verb|unpickle| with a single parameter of type \term{Pickle} and return type
\term{Unit}.
\end{defn}

The pickle method takes an object to-be-pickled of static type $T$, pickles it
by turning it into some external representation like a byte array, and returns
an instance of type \term{Pickle} which wraps the external representation. Given this
definition, picklers ``are type safe in the sense that a type-specialized
pickler can be applied only to values of the specialized type.''~\cite{Elsman2005}.

\paragraph{Preliminary Definitions.} To precisely specify the contracts of
picklers and unpicklers, we require standard definitions of the dynamic type
of an object \term{o}, written \itl{dynTypeOf(}\term{o}\itl{)}, and the erasure of a
static type $T$, written \itl{erasure(}$T$\itl{)}.

\begin{defn}(Structural Equality)

\noindent Two objects \term{obj}$_1$ and \term{obj}$_2$ are structurally equal, written

\begin{lstlisting}[escapechar=\%]
obj%$_1$% %$\equiv$% obj%$_2$%
\end{lstlisting}

\noindent if and only if

\begin{itemize}
\item \itl{dynTypeOf(}\term{obj$_1$}\itl{)} \term{=:=} \itl{dynTypeOf(}\term{obj$_2$}\itl{)} \term{=:=} $C$
      for some class type $C$, and we have that for all \term{fld} $\in$ $\textit{fields}(C)$.
      ~\term{obj$_1$.fld} $\equiv$ \term{obj$_2$.fld}, or
\item \itl{dynTypeOf(}\term{obj$_1$}\itl{)} \term{=:=} $T$ for some primitive type $T$, and \term{obj$_1$ == obj$_2$}.
\end{itemize}
\end{defn}

The contracts of \term{DPickler}s, \term{SPickler}s, and \term{Unpickler}s are
defined as follows.

\begin{defn}(Object-Oriented Picklers)

\noindent Given the following typed objects,

\begin{lstlisting}[escapechar=\%]
    dp: DPickler[%$T$%]
    sp: SPickler[%$T$%]
   obj: %$T$%
    up: Unpickler[%$U$%] %\textrm{where}% %$T <: U$%
  obj': %$U$%
\end{lstlisting}

\noindent where \term{obj} is the object to-be-pickled, and \term{obj'} is the unpickled
object. Then,

\begin{lstlisting}[escapechar=\%]
up.unpickle(dp.pickle(obj)) %\textrm{evaluates to}% obj'%\vspace{0.15cm}%
up.unpickle(sp.pickle(obj)) %\textrm{evaluates to}% obj' %\textrm{if}% %\textrm{\textit{dynTypeOf}(}%obj%\textrm{)}% =:= %\textrm{\textit{erasure}(}%T%\textrm{)}%
\end{lstlisting}

\noindent such that,

\begin{lstlisting}[escapechar=\%]
obj': U%\vspace{0.15cm}%
obj' %$\equiv$% obj
\end{lstlisting}
\end{defn}

Note that \term{SPickler}'s \term{pickle} method has a precondition which
requires the dynamic type of the object to-be-pickled to be equal to the
erasure of its static type $T$. This means that an \term{SPickler}$[T]$ is not
guaranteed to pickle any object of a subtype of $T$. Because of this
restriction we refer to instances of \term{SPickler} as {\em static picklers}.
In contrast, a \term{DPickler}$[T]$ pickles any object of type $T$. Therefore,
we refer to instances of \term{DPickler} as {\em dynamic picklers}.

In the following section, we motivate the distinction between static and
dynamic picklers.

\subsection{Modular Pickler Combinators}

Picklers as first-class objects make it possible to define pickler
combinators, which in turn make it possible to build compound picklers from
primitive picklers. However, only using the interface introduced above would
not allow us to achieve this, since calling into any of the component picklers
would produce a completed pickle; we would be left with the problem of
composing completed pickles which is inefficient in general. Since one of our
goals is high performance, we'll instead allow picklers to produce {\em
partial pickles} which themselves are essentially builders \cite{Gamma1995}
that multiple picklers can output to. The corresponding method has the
following signature:

\begin{lstlisting}
   def pickle(obj: T, builder: PickleBuilder): Unit
\end{lstlisting}

\verb|PickleBuilder| has methods to incrementally add elements of an object
to-be-pickled to a pickle that is being constructed (see Section
\ref{sec:pickleformat}). When all elements have been added to a
\verb|PickleBuilder|, calling \verb|result| returns the completed pickle.

For example, consider a simple class \verb|Position| with a field of type
String and a field of type \term{Person}, respectively:

\begin{lstlisting}
class Position(val title: String, val person: Person)
\end{lstlisting}

Modular pickler combinators would enable the composition of the desired
pickler for type \term{Position} from picklers for types \term{String} and
\term{Person}. However, note that the \term{person} field of a given instance
of class \term{Position} could point to an instance of a subclass of
\term{Person} (assuming class \term{Person} is not final). Therefore, a
modularly re-usable pickler for type \term{Person} must be able to pickle all
possible subtypes of \term{Person}.

In this case, the contract of static picklers is too strict, it does not allow
for subtyping. The contract of dynamic picklers on the other hand does allow
for subtyping. As a result, {\em dynamic picklers are necessary so as to enable
modular composition in the presence of subtyping}.

Picklers for final class types like \term{String}, or for primitive types like
\term{Int} do not require support for subtyping. Therefore, static picklers
are sufficient to pickle these {\em effectively final types}. Compared to
dynamic picklers, static picklers benefit from several optimizations that we
outline in more detail in Section~\ref{sec:optimize}.

\subsection{Implementing Object-Oriented Picklers}

The main challenge when implementing OO picklers comes from the fact that a
dynamic pickler for type $T$ must be able to pickle objects of any subtype of
$T$. Thus, the implementation of a dynamic pickler for type $T$ must, in
general, dynamically dispatch on the runtime type of the object to-be-pickled
to take into account all possible subtypes of $T$. Because of this dynamic
dispatch, manually constructing dynamic picklers can be difficult. It is
therefore important for a framework for object-oriented picklers to provide
good support for realizing this form of dynamic dispatching.

There are various ways across many different object-oriented programming
languages to handle subtypes of the pickler's static type:

\begin{itemize}
\item Data structures with shallow class hierarchies, such as lists or trees,
often have few final leaf classes. As a result, manual dispatch code is
typically simple in such cases. For example, a manual pickler for Scala's
\term{List} class does not even have to consider subclasses.

\item Java-style runtime reflection can be used to provide a generic
\term{DPickler}[$Any$] which supports pickling objects of any
type~\cite{JavaSerialization,Philippsen2000}. Such a pickler can be used as a
fallback to handle subtypes that are unknown to the pickling code; such
subtypes must be handled in the presence of separate compilation. In
Section \ref{sec:runtime-pickler} we present Scala implementations of such a
generic pickler.

\item Java-style annotation processing is commonly used to trigger the
generation of additional methods in annotated class types. The purpose of
generated methods for pickling would be to return a pickler or unpickler
specialized for an annotated class type. In C\#, the Roslyn
Project~\cite{Roslyn} allows augmenting class definitions based on the
presence of annotations.

\item Static meta programming \cite{Burmako2012,Nemerle} enables generation of
picklers at compile time. In Section~\ref{sec:generation} we present an
approach for generating object-oriented picklers from regular (class) type
definitions.
\end{itemize}

\subsection{Supporting Unanticipated Evolution}

Given the fact that the type \term{SPickler}[$T$], as introduced, has a type
parameter $T$, it is reasonable to ask what the variance of $T$ is. Ruling out
covariance because of $T$'s occurrence in a contravariant position as the type
of a method parameter, it remains to determine whether $T$ can be
contravariant.

For this, it is useful to consider the following scenario. Assume $T$ is
declared to be contravariant, as in \term{SPickler}[$-T$]. Furthermore, assume
the existence of a public, non-final class \term{C} with a subclass \term{D}:

\begin{lstlisting}
    class C {...}
    class D extends C {...}
\end{lstlisting}

Initially, we might define a generic pickler for \term{C}:

\begin{lstlisting}
    implicit val picklerC = new SPickler[C] {
      def pickle(obj: C): Pickle = { ... }
    }
\end{lstlisting}

Because \term{SPickler}[$T$] is contravariant in its type parameter, instances
of \term{D} would be pickled using \term{picklerC}. There are several possible
extensions that might be {\em unanticipated} initially:

\begin{itemize}
\item Because the implementation details of class \term{D} change, instances
of \term{D} should be pickled using a dedicated pickler instead of
\term{picklerC}.

\item A subclass \term{E} of \term{C} is added which requires a dedicated
pickler, since \term{picklerC} does not know how to instantiate class \term{E}
(since class \term{E} did not exist when \term{picklerC} was written).
\end{itemize}

In both cases it is necessary to add a new, dedicated pickler for either an
existing subclass (\term{D}) or a new subclass (\term{E}) of \term{C}:

\begin{lstlisting}
implicit val picklerD = new SPickler[D] { ... }
\end{lstlisting}

However, when pickling an instance of class \term{D} this new pickler,
\term{picklerD}, would not get selected, even if the type of the object to-be-pickled
is statically known to be \term{D}. The reason is that
\term{SPickler}[$C$] $<:$ \term{SPickler}[$D$] because of contravariance which
means that \term{picklerC} is more specific than \term{picklerD}. As a result,
according to Scala's implicit look-up rules \term{picklerC} is selected when
an implicit object of type \term{SPickler}[$D$] is required. (Note that this
is the case even if \term{picklerD} is declared in a scope that has higher
precedence than the scope in which \term{picklerC} is declared.)

While contravariant picklers do not support the two scenarios for
unanticipated extension outlined above, invariant picklers do, in combination
with type bounds. Assuming invariant picklers, we can define a generic method
\term{picklerC1} that returns picklers for all subtypes of class \term{C}:


\begin{lstlisting}
implicit def picklerC1[T <: C] = new SPickler[T] {
  def pickle(obj: T): Pickle = { ... }
}
\end{lstlisting}

With this pickler in scope, it is still possible to define a more specific
\term{SPickler}[$D$] (or \term{SPickler}[$E$]) as required:

\begin{lstlisting}
implicit val picklerD1 = new SPickler[D] { ... }
\end{lstlisting}

However, the crucial difference is that now \term{picklerD1} is selected when
an object of static type \term{D} is pickled, since \term{picklerD1} is more
specific than \term{picklerC1}.

\subsection{Summary}

This section has introduced an object-oriented model of first-class picklers.
Object-oriented picklers enable modular pickler combinators with support for
subtyping, thereby extending a well-known approach in functional programming.
The distinction between static and dynamic picklers enables optimizations for
final class types and primitive types. Object-oriented picklers can be
implemented using various techniques, such as manually-written picklers,
runtime reflection, or Java-style annotation processors. Finally, we argue
that object-oriented picklers should be invariant in their generic type
parameter to allow for several scenarios of unanticipated evolution.


\section{Generating Object-Oriented Picklers}
\label{sec:generation}

An explicit goal of our framework is to require little to no boilerplate in
client code, since practitioners are typically used to serialization supported
by the underlying runtime environment like in Java or .NET. Therefore, instead
of requiring libraries or applications to supply manually-written picklers for
all pickled types, our framework provides a component for {\em generating
picklers} based on their required static type.

What's more, compile-time pickler generation enables {\em efficient picklers}
by generating as much pickling code as possible statically (which corresponds
to a partial evaluation of pickler combinators). Section~\ref{sec:evaluation}
reports on the performance improvements that our framework achieves using
compile-time pickler generation, compared to picklers based on runtime
reflection, as well as manually-written picklers.

\begin{figure}
 \centering
 \includegraphics[width=\columnwidth]{generation.pdf}
 \caption{Illustration of pickle template for a sample JSON-formatted pickle.}
 \label{fig:generation}
\end{figure}

\subsection{Overview}

Our framework generates type-specialized, object-oriented picklers using
compile-time meta programming in the form of {\em macros}. Basically, whenever
a pickler for static type $T$ is required but cannot be found in the implicit
scope, a macro is expanded which generates the required pickler step-by-step
by:

\begin{itemize}
\item Obtaining a type descriptor for the static type of the object to-be-pickled,

\item Building a static {\em intermediate representation} of the object-to-be-pickled,
based on the type descriptor, and

\item Applying a pickler generation algorithm, driven by the static pickler
representation.
\end{itemize}

In our Scala-based implementation, the static type descriptor is generated
automatically by the compiler, and passed as an implicit argument to the
pickle extension method (see Section~\ref{sec:overview}). As a result, such an
implicit \term{TypeTag}\footnote{TypeTags are part of the mainline Scala
compiler since version 2.10. They replace the earlier concept of Manifests,
providing a faithful representation of Scala types at runtime, see Section
\ref{sec:background}.} does not require changing the invocation in most cases.
(However, it is impossible to generate a \term{TypeTag} automatically if the
type or one of its components is abstract; in this case, an implicit
\term{TypeTag} must be in scope.)

Based on the type descriptor, a static representation, or model, of the
required pickler is built; we refer to this as the {\em Intermediate
Representation} (IR). The IR specifies precisely the set of types for which
our framework can generate picklers automatically. These IRs are composable.

We additionally define a model for composing IRs, which is designed to capture
the essence of Scala's object system as it relates to pickling. The model
defines how the IR for a given type is composed from the IRs of the picklers
of its supertypes. In Scala, the composition of an IR for a class type is
defined based on the linearization of its supertraits.\footnote{Traits in
Scala can be thought of as a more flexible form of Java-style interfaces that
allow concrete members, and that support a form of multiple inheritance (mix-
in composition) that is guaranteed to be safe based on a linearization order.}
This model of inheritance is central to the generation framework, and is
formally defined in the following Section \ref{sec:ir}

\subsection{Formal Model of Inheritance}
\label{sec:ir}

\todo Need some text describing the IR

\begin{defn}{(Elements of IR)}

We define the syntax for values of the IR types.

\begin{align*}
F&        ::= \overline{(f_n, T)}\\
IR&       ::= (T, IR_{opt}, F)\\
IR_{opt}& ::= \epsilon~|~IR
\end{align*}

$F$ represents a sequence of \textit{fields}. We write $\overline{X}$ as
shorthand for sequences, $X_1,\dots,X_n$, and we write tuples
$(X_1,\dots,X_n)$. $f_n$ is a string representing the name of the given field,
and $T$ is its type.

$IR$ represents the pickling information for a class or some other object
type. That is, an $IR$ for type $T$ contains all of the information required
to pickle instances of type $T$, including all necessary static info for
pickling its fields provided by $F$.

$IR_{opt}$ is an optional $IR$; a missing $IR$ is represented using $\epsilon$.
\end{defn}
\label{def:elems-ir}

Using the definitions of the elements of an IR from Definition \ref{def:elems-ir},
we go on to define a number of useful IR combinators, which form the
basis of our model of inheritance.

\begin{defn}{(IR Combinators)}

We begin by defining the types of our combinators before we define the
combinators themselves.

\vspace{0.2cm}
{\bf Type Definitions}
{\small
\begin{align*}
\textit{concat}&        : (F, F) \Rightarrow F\\
\textit{extended}&      : (IR, IR) \Rightarrow IR\\
\textit{linearization}& : T \Rightarrow \overline{T}\\
\textit{superIRs}&      : T \Rightarrow \overline{IR}\\
\textit{compose}&       : IR \Rightarrow IR\\
\textit{flatten}&       : IR \Rightarrow IR
\end{align*}
}%

We write function types $X \Rightarrow Y$, indicating a function from type $X$
to type $Y$.

The \textit{linearization} function represents the host language's semantics for the
linearized chain of supertypes.\footnotemark[0]

\vspace{0.2cm}
{\bf Function Definitions}
{\small
\begin{align*}
\textit{concat}(\overline{f}, \overline{g})& = \overline{f}, \overline{g}\\
\textit{extended}(C, D)&                     = (T, C, \textit{fields}(T))\\
                       &                       \qquad \mbox{where}~D = (T, \_, \_)~\land T <: C.1\\
\textit{superIRs}(T)&                        = \lbrack(S, \epsilon, \textit{fields}(S))~|~S\in \textit{linearization}(T)\rbrack\\
\textit{compose}(C)&                         = \textit{reduce}(\textit{superIRs}(C.1),\textit{extended})\\
\textit{flatten}(C)&                         =\left\{ \begin{array}{l}
                                                (C.1, C.2, \textit{concat}(C.3, \textit{flatten(C.2).3})),\\
                                                \qquad\mbox{if}~C.2\neq\epsilon\\
                                                C,~~~\mbox{otherwise}
                                              \end{array} \right.
\end{align*}
}%

The function \textit{concat} takes two arguments that are each sequences. We
denote concatenation of sequences using a comma. We introduce the
\textit{concat} function for clarity in the definition of \textit{flatten}
(see below); it is simply an alias for sequence concatenation.

The function \textit{extended} takes two $IR$s, $C$ and $D$, and returns a new
$IR$ for the type of $D$ such that $C$ is registered as its super $IR$.
Basically, \textit{extended} is used to combine a completed $IR$ $C$ with an
incomplete $IR$ $D$ yielding a completed $IR$ for the same type as $D$. When
combining the $IR$s of a type's supertypes, the \textit{extended} function is
used for reducing the linearization sequence yielding a single completed $IR$.

The function \textit{superIRs} takes a type $T$ and returns a sequence of the
IRs of $T$'s supertypes in linearization order.

The function \textit{compose} takes an $IR$ $C$ for a type $C.1$ and returns a
new $IR$ for type $C.1$ which is the composition of the IRs of all supertypes
of $C.1$. The resulting $IR$ is a chain of super IRs according to the
linearization order of $C.1$.

The function \textit{flatten}, given an $IR$ $C$ produces a new $IR$ that
contains a concatenation of all the fields of each nested $IR$.

\end{defn}

\subsection{Pickler Generation Algorithm}

The pickler generation is driven by the IR (see Section~\ref{sec:ir}) of a
type to-be-pickled. We describe the generation algorithm in two steps. In the
first step, we explain how to generate a pickler for static type $T$ assuming
that for the dynamic type $S$ of the object to-be-pickled,
\textit{erasure}$(T) =:= S$. In the second step, we explain how to extend the
generation to dynamic picklers which do not require this assumption.

\subsubsection{Pickle Format}
\label{sec:pickleformat}

The pickling logic that we are going to generate contains calls to a pickle
{\em builder} that is used to incrementally construct a pickle. Analogously,
the unpickling logic contains calls to a pickle {\em reader} that is used to
incrementally read a pickle. Importantly, the pickle format that determines
the precise persisted representation of a completed pickle is not fixed.
Instead, the pickle format to be used is selected at compile time-- efficient
binary formats, and JSON are just some examples. This selection is done via
implicit parameters which allows the format to be flexibly selected while
providing a default binary format which is used in case no other format is
imported explicitly.

The pickle format provides an interface which plays the role of a simple,
lower-level ``backend''. Besides a pickle template that is generated inline as
part of the pickling logic, methods provided by pickle builders aim to do as
little as possible to minimize runtime overhead. For example,  the JSON
\term{PickleFormat} included with the Scala Pickling framework simply uses an
efficient string builder to concatenate JSON fragments (which are just
strings) in order to assemble a pickle.

% This is the footnote from the definition
\footnotetext[0]{For example, in Scala the linearization is
defined for classes mixing in multiple traits \cite{Odersky2005,ScalaSpec}; in
Java, the linearization function would simply return the chain of
superclasses, not including the implemented interfaces.}


The interface provided by \term{PickleFormat} is simple: it basically consists
of two methods (a) for creating an empty builder, and (b) for creating a
reader from a pickle:\footnote{In our actual implementation the
\term{createReader} method takes an additional parameter which is a "mirror"
used for runtime reflection; it is omitted here for simplicity.}

\begin{lstlisting}
    def createBuilder(): PBuilder
    def createReader(pickle: PickleType): PReader
\end{lstlisting}

The \term{createReader} method takes a pickle of a specific \term{PickleType}
(which is an abstract type member in our implementation); this makes it
possible to ensure that, say, a pickle encapsulating a byte array is not
erroneously attempted to be unpickled using the JSON pickle format. Moreover,
pickle builders returned from \verb|createBuilder| are guaranteed to produce
pickles of the right type.

\begin{lstlisting}
class PBuilder {
  def beginEntry(obj: Any): PBuilder
  def putField(n: String, pfun: PBuilder => Unit): PBuilder
  def endEntry(): Unit
  def result(): Pickle
}
\end{lstlisting}

In the following we're going to show how the \verb|PBuilder| interface is used
by generated picklers; the \verb|PReader| interface is used by generated
unpicklers in an analogous way. The above example summarizes a core
subset of the interface of \verb|PBuilder| that the presented generation
algorithm is going to use.\footnote{It is not necessary that \texttt{PBuilder}
is a class. In fact, in our Scala implementation it is a trait. In Java, it
could be an interface.} The \verb|beginEntry| method is used to indicate the
start of a pickle for the argument obj. The field values of a class instance
are pickled using \verb|putField| which expects both a field name and a lambda
encapsulating the pickling logic for the object that the field points to. The
\verb|endEntry| method indicates the completion of a (partial) pickle of an
object. Finally, invoking \verb|result| returns the completed \verb|Pickle|
instance.

\subsubsection{Tree Generation}

The objective of the generation algorithm is to generate the body of
\term{SPickler}'s \term{pickle} method:

\begin{lstlisting}
  def pickle(obj: T, builder: PBuilder): Unit = ...
\end{lstlisting}

As mentioned previously, the actual pickling logic is synthesized based on the
IR. Importantly, the IR determines which fields are pickled and how. A lot of
the work is already done when building the IR; therefore, the actual tree
generation is rather simple:

\begin{itemize}

\item Emit \verb|builder.beginEntry(obj)|.

\item For each field \term{fld} in the IR, emit \\\verb|builder.putField(${fld.name},b => pbody)|
where \\\verb|${fld.name}| denotes the splicing of \term{fld.name}
into the tree. \term{pbody} is the logic for pickling \term{fld}'s value into
the builder \term{b}, which is an alias of builder. \term{pbody} is generated
as follows:
  \begin{enumerate}

  \item Emit the field getter logic:
  \\\verb|val v: ${fld.tpe} = obj.${fld.name}|. The
  expression \verb|${fld.tpe}| splices the type of \term{fld} into the generated
  tree; \verb|${fld.name}| splices the name of \term{fld} into the tree.

  \item Recursively generate the pickler for \term{fld}'s type by emitting either
  \\\verb|val fldp = implicitly[DPickler[${fld.tpe}]]| or \verb|val fldp = implicitly[SPickler[${fld.tpe}]]|,
  depending on whether \term{fld}'s type is effectively final or not.

  \item Emit the logic for pickling \term{v} into \term{b}: \verb|fldp.pickle(v, b)|
  \end{enumerate}
\end{itemize}

A practical implementation can easily be refined to support various extensions
of this basic model. For example, support for avoiding pickling fields marked
as {\em transient} is easy with this model of generation-- such fields can
simply be left out of the IR. Or, based on the static types of the picklee and
its fields, we can emit hints to the builder to enable various optimizations.

For example, a field whose type $T$ is {\em effectively final}, \ie it cannot
be extended, can be optimized as follows:

\begin{itemize}
\item Instead of obtaining an implicit pickler of type \term{DPickler[T]}, it is
sufficient to obtain an implicit pickler of type \term{SPickler[T]}, which is
more efficient, since it does not require a dynamic dispatch step like
\term{DPickler[T]}

\item The field's type does not have to be pickled, since it can be reconstructed
from its owner's type.\footnote{Our implementation makes heavy use of this
optimization for pickling collections of primitives efficiently; see
Section~\ref{sec:optimize}.}
\end{itemize}

Pickler generation is compositional; for example, the generated pickler for a
class type with a string-typed field re-uses the string pickler. This is
achieved by generating picklers for parts of an object type using invocations
of the form \verb|implicitly[DPickler[T]]|. This means that if there is
already an implicit value of type \term{DPickler[T]} in scope, it is used for
pickling the corresponding value. Since the lookup and binding of these
implicit picklers is left to a mechanism outside of pickler generation, what's
actually generated is a {\em pickler combinator} which returns a {\em pickler}
composed of {\em existing picklers} for parts of the object to-be-pickled.
More precisely, pickler generation provides the following composability
property:

\begin{prop}{(Composability)}
A generated pickler \term{p} is composed of implicit picklers of the required
types that are in scope at the point in the program where \term{p} is
generated.
\end{prop}

Since the picklers that are in scope at the point where a pickler is generated
are under programmer control, it is possible to import manually-written
picklers which are transparently picked up by the generated pickler. Our
approach thus has the attractive property that it is an ``open-world''
approach, in which it is easy to add new custom picklers for selected types at
exactly the desired places while integrating cleanly with generated picklers.

\subsubsection{Dispatch Generation}

So far, we have explained the generation of the pickling logic of static
picklers. Dynamic picklers require an additional dispatch step to make sure
subtypes of the static type to-be-pickled are pickled properly. The generation
of a \term{DPickler[T]} is triggered by invoking
\verb|implicitly[DPickler[T]]| which tries to find an implicit of type
\term{DPickler[T]} in the current implicit scope. Either there is already an
implicit value of the right type in scope, or the only matching implicit is an
implicit def provided by the pickling framework which generates a
\term{DPickler[T]} on-the-fly. The generated dispatch logic has the following
shape:

\begin{lstlisting}
    val clazz = if (picklee != null) picklee.getClass else null
    val pickler = clazz match {
      case null => implicitly[SPickler[NullTpe]]
      case c1 if c1 == classOf[S1] => implicitly[SPickler[S1]]
      ...
      case cn if cn == classOf[Sn] => implicitly[SPickler[Sn]]
      case _ => genPickler(clazz)
    }
\end{lstlisting}

The types $S1, \dots, Sn$ are known subtypes of the picklee's type $T$. If $T$
is a sealed class or trait with final subclasses, this set of types is always
known at compile time. However, in the presence of separate compilation it is,
generally, possible that a picklee has an unknown runtime type; therefore, we
include a default case (the last case in the pattern match) which dispatches
to a runtime pickler that inspects the picklee using (runtime) reflection.

If the static type $T$ to be pickled is annotated using the
\term{$@$pickleable} annotation, all subclasses are guaranteed to extend the
predefined \verb|HasPickler| interface trait. Consequently, a more optimal
dispatch can be generated in this case:

\begin{lstlisting}
    val pickler =
      if (picklee != null) {
        val hasp = picklee.asInstanceOf[HasPickler]
        hasp.getPickler.asInstanceOf[SPickler[T]]
      }
      else implicitly[SPickler[NullTpe]]
\end{lstlisting}

\subsection{Runtime Picklers}
\label{sec:runtime-pickler}

One goal of our framework is to generate as much pickling code at compile time
as possible. However, due to the interplay of subclassing with both separate
compilation and generics, we provide a runtime fall back capability to handle
the cases that cannot be resolved at compile time.

{\bf Subclassing and separate compilation}: A situation arises where it's
impossible to statically know all possible subclasses. In this case there are
three options: (1) provide a custom pickler, and (2) use an annotation which
is described in Section \ref{sec:pickleable-annotation}. In the case where
neither a custom pickler nor an annotation is provided, our framework can
inspect the instance to-be-pickled at runtime to obtain the pickling logic.
This comes with some runtime overhead, but in Section \ref{sec:evaluation} we
present results which suggest that this overhead is not necessary in many
cases.

For the generation of runtime picklers our framework supports two possible
strategies:

\begin{itemize}
\item Runtime interpretation of a type-specialized pickler
\item Runtime compilation of a type-specialized pickler
\end{itemize}

\paragraph{Interpreted runtime picklers.} If the runtime type of an object is
unknown at compile time, e.g., if its static type is \term{Any}, it is
necessary to carry out the pickling based on inspecting the type of the object
to-be-pickled at runtime. We call picklers operating in this mode ``interpreted
runtime picklers'' to emphasize the fact that the pickling code is not
partially evaluated in this case. An interpreted pickler is created based on
the runtime class of the picklee. From that runtime class it is possible to
obtain a runtime type descriptor.

\begin{itemize}
\item to build a static intermediate representation of the type (which describes all its fields with their types, etc.)
\item to determine in which way the picklee should be pickled (as a primitive or not).
\end{itemize}

In case the picklee is of primitive type, there are no fields to be pickled.
Otherwise, the value and runtime type of each field is obtained, so that it
can be written to the pickle.

\todo We mention in the bulleted list above runtime compilation but don't explain it

\subsection{Generics}

{\bf Subclassing and generics}: The combination of subclassing and generics
poses a similar problem to that introduced above in Section \ref{sec:runtime-pickler}.
For example, consider a generic class \term{C},

\begin{lstlisting}
    class C[T](val fld: T) { ... }
\end{lstlisting}

A \term{Pickler[C[T]]} will not be able to pickle the field \term{fld} if its
static type is unknown. To support pickling instances of generic classes, our
framework falls back to using runtime picklers for pickling fields of generic
type. So, when we have access to the runtime type of field \term{fld}, we can
either look up an already-generated pickler for that runtime type, or we can
generate a suitable pickler dynamically.



\section{Implementation}

The presented framework has been fully implemented in Scala.\footnote{A
preview of the pickling framework is made available by the authors upon
request.} The object-oriented pickler combinators presented in
Section~\ref{sec:oopicklers}, including their implicit selection and
composition, can be implemented using stable versions of the standard, open-
source Scala distribution. The component that extends our basic model with
automatic pickler generation has been implemented using the experimental
macros feature introduced in Scala 2.10.0 (January 2013). Macros are being
used as a more regularly structured and more stable alternative to compiler
plugins. To simplify tree generation, our implementation leverages a
quasiquoting library for Scala's macros.~\cite{Quasiquotes}.



\subsection{Optimizations}
\label{sec:optimize}

\section{Temporary TODOs}

\subsection{Recursive Types}

\todo what to do with this?

Recursive types are used in many common data structures like lists, trees etc. Here we show how recursive types are supported in our framework.

Example (we show a non-generic class hierarchy for simplicity):

\begin{lstlisting}
    abstract class IntTree
    class Empty extends IntTree
    class Fork(left: IntTree, elem: Int, right: IntTree)
\end{lstlisting}

\section{Experimental Evaluation}
\label{sec:evaluation}

In this section we present first results of an experimental evaluation
of our pickling framework. We have the following goals:
\begin{enumerate}
\item evaluate the performance of automatically-generated picklers
  compared to manually-written picklers, analyzing the memory usage
  compared to other serialization frameworks,
\item provide a survey of the properties of data types that are
  commonly used in distributed computing frameworks and applications,
  and
\item evaluate the potential impact of our framework on code
  maintenance in comparison with the same frameworks used for
  performance evaluation.
\end{enumerate}\noindent
In the process we are going to evaluate the performance of our
framework alongside two of the most important serialization frameworks
for the JVM, Java's native serialization and Kryo.

\subsection{Experimental Setup}

The following benchmarks were run on a MacBook Pro with a 2.7 GHz
Intel Core i7 processor with 16 GB of memory running Mac OS X version
10.8.2 and Oracle's Java HotSpot(TM) 64-Bit Server VM version
1.6.0\_43. In all cases we used the following configuration flags:
\texttt{-Xms1536M -Xmx4096M -Xss2M -XX:MaxPermSize=512M -XX:+UseParallelGC}.

\paragraph{Microbenchmark: collections.} In the first microbenchmark
we evaluate the performance of our framework when pickling standard
collection types. We compare against three other serialization
frameworks: Java's native serialization, Kryo, and a combinator
library of manually-written picklers. All benchmarks are compiled and
run using Scala version 2.9.3, except for the present framework which
depends on an experimental macro system, as well as a couple of minor
bug fixes that exist only in a current development version of Scala.

The benchmark logic is very simple: an immutable collection of type
\verb|Vector[Int]| is created which is first pickled (or serialized)
to a byte array, and then unpickled. We chose to use Vectors, because
Scala's standard List type could not be serialized out-of-the-box
using Kryo, because it is a recursive type in Scala. The results are
shown in Figure~\ref{fig:results-vector} As can be seen, the
performance of our prototype is essentually on par with Kryo; for
smaller and medium-sized collections even slightly higher. The
performance of manually-written pickler combinators, however, is still
notably better. In principle, it should be possible to generate code
that is as fast as these pickler combinators at least in the case
where static picklers can be generated.

Figure~\ref{fig:memory} shows the corresponding memory usage; on the
y-axis the value of \texttt{System.freeMemory} is shown. This plot
reveals an crucial property of Kryo, namely (a) that its memory usage
is quite high compared to other frameworks, and (b) that it
serialization is stateful because of internal buffering. In fact, when
preparing these benchmarks we had to manually adjust Kryo buffer sizes
to avoid buffer overflows. It turns out the main reason for this is
that Kryo reuses buffers whenever possible when serializing one object
after the other. In many (most?) cases the newly pickled object is
simply append at the current position in the existing buffer which
results in unexpected buffer growth. Our framework does not do any
buffering which makes its behavior very predictable, but does not
necessarily maximize its performance.



(1) GeoTrellis (https://github.com/geotrellis/geotrellis)
GeoTrellis is an open source high performance geoprocessing engine that transforms user interaction with geospatial data through speed and scale.
Types (Java Serialization):
final case class DoubleConstant(n: Double, cols: Int, rows: Int) extends StrictRasterData

final case class IntConstant(n: Int, cols: Int, rows: Int) extends StrictRasterData

final case class BitArrayRasterData(array: Array[Byte], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

final case class ByteArrayRasterData(array: Array[Byte], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

final case class DoubleArrayRasterData(array: Array[Double], cols: Int, rows: Int) extends MutableRasterData with DoubleBasedArray

final case class FloatArrayRasterData(array: Array[Float], cols: Int, rows: Int) extends MutableRasterData with DoubleBasedArray

final case class IntArrayRasterData(array: Array[Int], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

final case class ShortArrayRasterData(array: Array[Short], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

Comments: MutableRasterData and IntBasedArray are just traits that do not contain data.

Can we get a GeoTrellis app to run?

{\bf Survey of apps}

\begin{itemize}
\item take 10 or so apps, look at which types are pickled. Then we say which ones we support. and then we can point to microbenchmarks to show how it performs for that type.
\item first step: find real apps that are distributed
\item check Samira's paper, she has pointed out which actor apps are distributed
\item for Spark: every Spark is distributed, so we just have to find out which types are put into the RDDs. These element types are the ones we need to serialize.
\end{itemize}

\section{Related Work}
\label{sec:related-work}

\todo cite Haskell deriving!

Figure~\ref{fig:comparison} compares the main pickling/serialization
frameworks with respect to type-safety, object-orientation, type
extensibility, and format extensibility.

\begin{figure*}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
Framework           & Type-safety  & Object-oriented  & Boilerplate-free  & Type extensibility  & Format Extensibility \\
\hline
Java Serialization  & Java-only    & yes              & yes          & no                  & no \\
Kryo                & Java-only    & yes              & yes          & yes                 & no \\
Pickler combinators & yes          & no               & no           & yes                 & (yes) \\
Scala picklers      & yes          & yes              & yes          & yes                 & yes \\
\hline
\end{tabular}

\caption{Comparing serialization frameworks}\label{fig:comparison}
\end{figure*}

\section{Future Work}

\section{Conclusion}

\begin{figure*}[ht!]
 \centering
 \includegraphics{application-table.pdf}
 \caption{Applications of language features in existing commercial distributed frameworks/applications.}
 \label{fig:application-table}
\end{figure*}

% \begin{table*}
% \centering
% \begin{tabular}{l c c c c c c c}
% \toprule % Top horizontal line
% & primitives/ & value-like & collections & case & type & generics & ad-hoc \\ % Column names row
% & primitive arrays & types &  & classes & descriptor &  & polymorphism \\ % Column names row
% \midrule % In-table horizontal line
% GeoTrellis (Akka) & $\CIRCLE$ & $\Circle$     & $\Circle$     & $\CIRCLE$ & $\Circle$     & $\Circle$     & $\Circle$ \\
% Evactor (Akka)    & $\CIRCLE$ & $\LEFTcircle$ & $\LEFTcircle$ & $\CIRCLE$ & $\Circle$     & $\Circle$     & $\LEFTcircle$ \\
% \midrule % In-table horizontal line
% Spark             & $\CIRCLE$ & $\CIRCLE$     & $\CIRCLE$     & N/A       & $\Circle$     & $\Circle$     & N/A \\
% Storm             & $\Circle$ & $\CIRCLE$     & $\CIRCLE$     & N/A       & $\Circle$     & $\Circle$     & $\LEFTcircle$ \\
% Twitter Chill     & $\Circle$ & $\LEFTcircle$ & $\CIRCLE$     & N/A       & $\LEFTcircle$ & $\LEFTcircle$ & $\LEFTcircle$ \\
% \bottomrule % Bottom horizontal line
% \end{tabular}
% % \caption{Table caption text} % Table caption, can be commented out if no caption is required
% % \label{tab:template} % A label for referencing this table elsewhere, references are used in text as \ref{label}
% \end{table*}

A reference to Table \ref{tab:template}.


% \appendix
% \section{Appendix Title}

% This is the text of the appendix, if you need one.

% \acks

% Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.


% The bibliography should be embedded for final submission.

%\begin{thebibliography}{}
%\softraggedright

%\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
%P. Q. Smith, and X. Y. Jones. ...reference text...

%\end{thebibliography}

\begin{spacing}{0.9}
\bibliographystyle{abbrvnat}
\bibliography{bib}
\end{spacing}

\end{document}
