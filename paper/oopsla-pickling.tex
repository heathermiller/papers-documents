%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint,10pt]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{color}
\usepackage{listings,xspace}
\usepackage{amsthm}
\usepackage{mdframed}

\lstdefinelanguage{Scala}%
{morekeywords={abstract,case,catch,char,class,%
    def,else,extends,final,%
    if,import,%
    match,module,new,null,object,override,package,private,protected,%
    public,return,super,this,throw,trait,try,type,val,var,with,implicit,%
  },%
  sensitive,%
  morecomment=[l]//,%
  morecomment=[s]{/*}{*/},%
  morestring=[b]",%
  morestring=[b]',%
  showstringspaces=false%
}[keywords,comments,strings]%

\lstset{language=Scala,%
  mathescape=true,%
  columns=[c]fixed,%
  basewidth={0.5em, 0.40em},%
  basicstyle=\tt,%
  xleftmargin=0.0cm
}

\makeatletter
\def \@ivtitleauthors#1#2#3#4{%
  \if \@andp{\@emptyargp{#2}}{\@emptyargp{#3}}%
    \noindent \@setauthor{40pc}{#1}{\@false}\par
  \else\if \@emptyargp{#3}%
    \noindent \@setauthor{17pc}{#1}{\@false}\hspace{3pc}%
              \@setauthor{17pc}{#2}{\@false}\par
  \else\if \@emptyargp{#4}%
    \noindent \@setauthor{17pc}{#1}{\@false}\hspace{3pc}%
              \@setauthor{17pc}{#3}{\@false}\par
  \else
    \noindent \@setauthor{9.3333pc}{#1}{\@false}\hspace{1.5pc}%
              \@setauthor{9.3333pc}{#2}{\@false}\hspace{1.5pc}%
              \@setauthor{9.3333pc}{#3}{\@false}\hspace{1.5pc}%
              \@setauthor{9.3333pc}{#4}{\@true}\par
    \relax
  \fi\fi\fi
  \vspace{20pt}}
\def \@maketitle {%
  \begin{center}
  \@settitlebanner
  \let \thanks = \titlenote
  {\leftskip = 0pt plus 0.25\linewidth
   \rightskip = 0pt plus 0.25 \linewidth
   \parfillskip = 0pt
   \spaceskip = .7em
   \noindent \LARGE \bfseries \@titletext \par}
  \vskip 6pt
  \noindent \Large \@subtitletext \par
  \vskip 12pt
  \ifcase \@authorcount
    \@latex@error{No authors were specified for this paper}{}\or
    \@titleauthors{i}{}{}\or
    \@titleauthors{i}{ii}{}\or
    \@titleauthors{i}{ii}{iii}\or
    \@ivtitleauthors{i}{ii}{iii}{iv}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\@titleauthors{x}{}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\@titleauthors{x}{xi}{}\or
    \@titleauthors{i}{ii}{iii}\@titleauthors{iv}{v}{vi}%
                  \@titleauthors{vii}{viii}{ix}\@titleauthors{x}{xi}{xii}%
  \else
    \@latex@error{Cannot handle more than 12 authors}{}%
  \fi
  \vspace{1.75pc}
  \end{center}}
\makeatother

\theoremstyle{definition}
\newmdtheoremenv[hidealllines=true,topline=true,bottomline=true,skipabove=\baselineskip,skipbelow=\baselineskip]{defn}{Definition}[section]
% \newtheorem{defn}{Definition}[section]
% \newenvironment{defn}
  % {\begin{mdframed}[style=warning]\begin{mdef}}
  % {\end{mdef}\end{mdframed}}

\newcommand{\todo}{{\bf \colorbox{red}{\color{white}TODO:}}}
\newcommand{\ie}{{\em i.e.,~}}
\newcommand{\eg}{{\em e.g.,~}}
\newcommand{\term}[1]{\mbox{\texttt{#1}}}
\newcommand{\itl}[1]{\mbox{\textit{#1}}}

\begin{document}

\conferenceinfo{OOPSLA '13}{October 26-31, Indianapolis, IN, USA.}
\copyrightyear{2013}
\copyrightdata{[to be supplied]}

% \titlebanner{banner above paper title}        % These are ignored unless
% \preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Object-Oriented Pickler Combinators}
\subtitle{and an Extensible Generation Framework}

\authorinfo{Heather Miller}
           {EPFL, Switzerland}
           {heather.miller@epfl.ch}
\authorinfo{Philipp Haller}
           {Typesafe, Switzerland}
           {philipp.haller@typesafe.com}
\authorinfo{Eugene Burmako}
           {EPFL, Switzerland}
           {eugene.burmako@epfl.ch}
\authorinfo{Martin Odersky}
           {EPFL, Switzerland}
           {martin.odersky@epfl.ch}

\maketitle

\begin{abstract}

Serialization or pickling, i.e., persisting runtime objects by converting them
into a binary or text representation is ubiquitous in distributed programming.
Pickler combinators are a popular approach from functional programming designed to
alleviate some of the tedium of writing pickling code by hand, but they don't
translate well to object-oriented programming due to qualities like open class
hierarchies and ad-hoc polymorphism. Furthermore, both functional pickler
combinators and Java-based serialization frameworks tend to be tied to a
specific pickle format, leaving programmers no choice of how their data is
persisted. In this paper, we present object-oriented pickler combinators and a
framework for generating them at compile-time, designed to be the default
serialization mechanism of the Scala programming language. Our framework is
extensible; (1) using Scala's implicit parameters, users can add their own
easily-swappable pickle format, (2) using the type class pattern, users can
provide their own custom picklers to override the default behavior of the
Scala pickling framework. In addition to extensibility and need for little to
no boilerplate, the static generation of our OO picklers achieves an order of
magnitude speedup over Java Serialization and up to a factor 7 speedup over
popular ``fast'' Java serialization frameworks like Kryo.
\todo mention Akka \& Spark?
% We go on to evaluate
% our framework on two large industrial-strength frameworks for distributed
% computing, Akka and Spark, and show improved performance and a reduction of
% lines of serialization-related code for both projects.

\end{abstract}

\category{D.3.2}{Programming Languages}{Language Classifications --
  multiparadigm languages, object-oriented languages, applicative
  (functional) languages}
\category{D.3.3}{Programming Languages}{Language Constructs and
  Features -- input/output}

% \terms
% term1, term2

\keywords
Serialization, pickling, meta-programming, distributed programming, Scala

\section{Introduction}

With the growing trend towards cloud computing and mobile applications,
distributed programming has entered the mainstream. As more and more
traditional applications migrate to the cloud, the demand for interop between
different services is at an all-time high, and is increasing. At the center of
it all is communication. Whether we consider a cluster of commodity machines
churning through a massive data-parallel job, or a smartphone interacting with
a social network, all are ``distributed'' jobs, and all share the need to
communicate in various ways, in many formats, even within the same
application.

A central aspect to this communication that has received suprisingly little
attention in the literature is the need to serialize, or {\em pickle} objects
{\em i.e.,} to persist in-memory data by converting them to a binary, text, or
some other representation. On the JVM, serialization has long been
acknowledged as having a high overhead \cite{Welsh2000, Carpenter1999}, with
some estimates purporting object serialization to account for 25-65\% of the
cost of remote method invocation, and which go on to observe that the cost of
serialization grows with growing object structures up to 50\%
\cite{Philippsen2000, Maassen1999}.

Due to the prohibitive cost of using Java Serialization in high-performance
distributed applications, many frameworks for distributed computing, like
Akka~\cite{Akka}, Spark~\cite{Zaharia2012}, SCADS \cite{Armbrust2009}, and
others, provide support for higher-performance alternative frameworks such as
Google's Protobuf~\cite{Protobuf}, Apache Avro~\cite{Avro}, or
Kryo~\cite{Kryo}. However, the higher efficiency typically comes at the cost
of weaker or no type safety, a fixed serialization format, more restrictions
placed on the objects to-be-serialized, or only rudimentary language
integration.

This paper takes a step towards more principled open programming through a new
foundation for pickling in object-oriented languages. We present object-oriented
picklers and a framework for generation either at runtime or at
compile time. The introduced notion of object-oriented pickler combinators
extends pickler combinators known from functional
programming~\cite{Kennedy2004} with support for object-oriented concepts such
as subtyping and mix-in composition. In contrast to pure functional-style
pickler combinators, we employ static, type-based meta programming to compose
picklers at compile time. The resulting picklers are efficient, since the
pickling code is generated statically as much as possible, avoiding the
overhead of runtime reflection~\cite{Gil2008,Dubochet2011}.

What's more, the presented pickling framework is extensible in several
important ways. First, building on an object-oriented type-class-like
mechanism~\cite{Oliveira2010}, our approach enables retroactively adding
pickling support to existing, unmodified types. Second, our framework provides
pluggable pickle formats which decouple type checking and pickler composition
from the lower-level aspects of data formatting. This means that the type
safety guarantees provided by type-specialized picklers are ``portable'' in
the sense that they carry over to different pickle formats.

The design of our framework has been guided by the following principles:
\begin{itemize}
\item {\bf Ease of use}. The programming interface aims to require as little
pickling boilerplate as possible. Thanks to dedicated support by the
underlying virtual machine, Java's serialization~\cite{JavaSerialization}
requires only little boilerplate, which mainstream Java developers have come
to expect. Our framework aims to be useable in production environments, and
must, therefore, be able to integrate with existing systems with minimal
changes.

\item {\bf Performance}. The generated picklers should be efficient enough  so
as to enable their use in high-performance distributed, ``big data'', and
cloud applications. One factor driving practitioners away from Java's default
serialization mechanism is its high runtime overhead compared to alternatives
such as Kryo, Google's protocol buffers or Apache's Avro serialization
framework. However, frameworks such as the latter offer only minimal language
integration.

\item {\bf Extensibility}. It should be possible to add pickling support to existing
types retroactively. This resolves a common issue in Java-style serialization
frameworks where classes have to be marked as serializable upfront,
complicating unanticipated change. Furthermore, type-class-like extensibility
enables pickling also for types provided by the underlying runtime environment
(including built-in types), or types of 3rd party libraries.

\item {\bf Pluggable Pickle Formats}. It should be possible to easily swap target
pickle formats, or for users to provide their own customized format. It is not
uncommon for a distributed application to require multiple formats for
exchanging data, for example an efficient binary format for exchanging system
messages, or JSON format for publishing feeds. Type-class-like extensibility
makes it possible for users to define their own pickle format, and to easily
{\em swap it in} at the use-site.

\item {\bf Type safety}. Picklers should be type safe through (a) type
specialization and (b) dynamic type checks when unpickling to transition
unpickled objects into the statically-typed ``world'' at a well-defined program
point.

\item {\bf Robust support for object-orientation}. Concepts such as subtyping and
mix-in composition are used very commonly to define regular object types in
object-oriented languages. Since our framework does without a separate data
type description language ({\em e.g.,} a schema), it is important that regular
type definitions are sufficient to describe the types to-be-pickled. The
Liskov substitution principle is used as a guidance surrounding the
substitutability of both objects to-be-pickled and first-class picklers.
\end{itemize}


\subsection{Related Work}

Some OO languages like Java and runtime environments like the JVM or .NET
provide serialization for arbitrary types, provided by the underlying virtual
machine. While this approach is very convenient for the programmer there are
also several issues: (a) the pickling format cannot be exchanged (Java), (b)
serialization relies on runtime reflection which hits performance, and (c)
existing classes that do not extend a special marker interface are not
serializable, which often causes oversights resulting in software engineering
costs. JavaScript has direct support for serialization in the form of JSON
(unpickle = eval). In functional languages, pickler combinators can reduce the
effort of manually writing pickling and unpickling functions to a large
extent. However, existing approaches do not support object-oriented concepts
such as ad-hoc polymorphism. Moreover, it is not clear whether local type
inference as required in OO languages would yield a comparable degree of
conciseness, acceptable to programmers used to Java-style serialization.
Nonetheless, our approach builds on PCs because of their superior
composability. We discuss further, less-closely related work in Section ??.
\todo Add section. Finish up related work.

\subsection{Contributions}

This paper makes the following contributions:

\begin{itemize}

\item An extension to pickler combinators, well-known in functional
programming,  to support the core concepts of object-oriented programming,
namely open class hierarchies and ad-hoc polymorphism.

\item A framework based on object-oriented pickler combinators which (a)
enables retrofitting existing types with pickling support, (b) supports
automatically generating picklers at compile time and at runtime, (c) supports
pluggable pickle formats, and (d) does not require changes to the host
language or the underlying virtual machine.

\item A complete implementation of the presented approach in and for Scala \footnote{See
    \texttt{http://github.com/heathermiller/scala-pickling/}}.

\item An experimental evaluation comparing the performance of our framework
with Java serialization and Kryo. In microbenchmarks our framework outperforms
Java serialization by a factor of X and Kryo by a factor of Y. We also
evaluate the performance on a set of data types used in large industrial-
strength distributed computing frameworks and applications, and show an
integration in Spark and Akka.

\end{itemize}

\subsection{Temporary TODOs}

For introduction, and points we don't want to lose.

\todo make nod to "open programming" \cite{Rossberg2007}, motivation for strongly-typed languages to easily communicate with one another?

\todo Reference to Scrap Your Boilerplate \cite{Lammel2004}.

From the Scrap Your Boilerplate\#2 paper:
\begin{quote}
It is common to find that large slabs of a program consist of ``boilerplate'' code, which conceals by its bulk a smaller amount of ``interesting'' code. So-called generic programming techniques allow programmers to automate this ``boilerplate'', allowing effort to be focused on the interesting parts of the program.
\end{quote}

\todo Our approach has several attractive properties: it is an ``open-world'' approach, in which it is easy to add new customized picklers at exactly the desired places;

\todo Even the fastest Java serialization frameworks must generate all
pickler-related code at runtime, which in preliminary benchmarks
amounts to a factor 10 slow-down over a naive but fully-static handwritten pickler
combinator-based approach.

\todo The goal of this project is a new framework for pickling (or
serialization). The idea is to automatically generate pickler
combinators at compile-time.

\todo PC of FP do not support subtyping. Even if they would, it is not clear whether local type inference as required in OO would be enough to support the same level of conciseness as in FP.

Figure~\ref{fig:comparison} compares the main pickling/serialization
frameworks with respect to type-safety, object-orientation, type
extensibility, and format extensibility.

\begin{figure*}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
Framework           & Type-safety  & Object-oriented  & Boilerplate-free  & Type extensibility  & Format Extensibility \\
\hline
Java Serialization  & Java-only    & yes              & yes          & no                  & no \\
Kryo                & Java-only    & yes              & yes          & yes                 & no \\
Pickler combinators & yes          & no               & no           & yes                 & (yes) \\
Scala picklers      & yes          & yes              & yes          & yes                 & yes \\
\hline
\end{tabular}

\caption{Comparing serialization frameworks}\label{fig:comparison}
\end{figure*}

\todo can handle constructors (TODO: verify that Kryo cannot)

\todo framework which generates picklers through composition

\todo Problem: does not work with ctors with parameters which do side effects. in this respect, we're the same as Java

\todo What do we do with this contribution section? Should be merged with the one above?

\begin{itemize}

\item A new pickling framework for object-oriented languages that (a)
  is fast through compile-time generated picklers, (b) enables
  retrofitting pickling support to existing types retroactively, (c)
  supports pluggable pickling formats, and (d) does not require
  changes to the underlying VM.

  The framework is thus extensible in several dimensions: first,
  pickling can be enabled for classes that have not been prepared
  beforehand (through extending a specific interface, for
  example). Second, new pickling formats (JSON, XML, Protobuf, etc.)
  can be added and selected modularly.

\item Our approch extends pickler combinators (a well-established
  approach in the functional programming
  community~\cite{Kennedy,Elsman}) to support core concepts of
  object-oriented programming, namely open class hierarchies and
  ad-hoc polymorphism (runtime dispatch).

\item To the best of our knowledge we are the first to extend pickler
  combinators with pluggable pickling formats.

\item We present a complete implementation of our approach in
  Scala.\footnote{See
    \texttt{http://github.com/heathermiller/scala-pickling/}} We have
  evaluated our framework by comparing its performance with the native
  serialization support of the Java Virtual Machine, as well as the
  Kryo serialization framework~\cite{Kryo} for Java. In the context of
  a suite of microbenchmarks, our framework outperforms Java
  serialization by a factor of X, and Kryo by a factor of Y. We have
  also integrated our pickling framework in Spark~\cite{Zaharia2010}
  and Akka~\cite{Akka}, and found that on representative applications
  our pickling framework improves performance by $X \%$ (Spark) and $Y
  \%$ (Akka) on average without requiring changes in user code.

\end{itemize}


\section{Background}

The design and implementation of our pickling framework leverages
several advanced features of the Scala programming language. This
section introduces everything that is required to understand the rest
of the paper. Apart from this section the reader is expected to be
familiar with a typical statically-typed, class-based object-oriented
programming language such as Java or C\#.

\subsection{Implicits}
\label{sec:implicits}

In Scala it is possible to select arguments to be passed to methods
automatically based on their type. For example, a method \verb|log| with
multiple parameter lists may annotate their last parameter list using the
\verb|implicit| keyword.


cite Adriaan's and Bruno's OOPSLA paper.
Example of a type class: maybe Ordering type class of std lib?
%~\cite{Olivera2010}

Include info on importing implicit values, and implicit resolution by scoping.
% \paragraph{Importing implicit values}
% (is this subsection actually necesssary?)
% Example of a plain implicit parameter: could use implicit ExecutionContext in futures

\subsection{Reflection}

Reflection is the ability of a program to inspect, and possibly even modify
itself at runtime. Before Scala 2.10, Scala did not have any reflection
capabilities of its own. Instead, one could use Java reflection which provided
a very limited subset of runtime reflection capabilities. In Scala 2.10, a new
reflection library was introduced not only to address the shortcomings of
Java's runtime reflection on Scala-specific and generic types, but to also add
a more powerful toolbox of general reflective capabilities to Scala. Along
with full-featured runtime reflection for Scala types and generics, Scala 2.10
also ships with compile-time reflection capabilities, in the form of macros
(covered in Section \ref{sec:macros}), as well as the ability to reify Scala
expressions into abstract syntax trees.

\paragraph{TypeTags.} One aspect of runtime reflection that was introduced in
Scala 2.10 is the notion of \verb|TypeTag|s. As with other JVM languages,
Scala's types are erased at compile time. \verb|TypeTag|s can be thought of as
objects which carry along all type information available at compile time, to
runtime. As we will see, \verb|TypeTag|s will prove to be invaluable in
situations where precise type information is not available at runtime.

\paragraph{Unified Runtime/Compile-time Reflection API.} Another important
aspect of Scala's reflection library is the one-to-one correspondence between
Scala Reflection's compile-time (\ie macros) and runtime APIs. Each API is
parameterized on a so-called \verb|Universe|, an object which serves as the
entry point to Scala reflection, and which provides all principal concepts
used in reflection, such as \verb|Type|s, \verb|Tree|s, and
\verb|Annotation|s. Depending on the task at hand, the choice between runtime
and compile-time reflection is as easy as selecting either a compile-time or a
runtime \verb|Universe|, and using the unified runtime/compile-time reflection
API provided by Scala Reflection. As we will see, this enables maximum code
reuse in that a fallback runtime pickler generation mechanism can be achieved
by simply reusing the code for static generation, and parameterizing it on a
runtime \verb|Universe|.


\subsection{Macros}
\label{sec:macros}

Scala reflection enables a form of metaprogramming which makes it possible for
programs to modify themselves at compile-time. This compile-time reflection is
realized in the form of hygenic macros \cite{Burmako2012}, which {\em expand}
at compile-time to manipulate abstract syntax trees (ASTs). In our framework, we make
use of two principal types of macros.

\paragraph{Macro defs.} Macro defs are methods that are transparently loaded
by the compiler and executed (or expanded) during compilation. A macro is
defined as if it is a normal method, but it is linked using the \verb|macro|
keyword to an additional method that operates on abstract syntax trees.

\begin{lstlisting}
def assert(x: Boolean, msg: String): Unit =
  macro assert_impl
def assert_impl(c: Context)
  (x: c.Expr[Boolean], msg: c.Expr[String]):
                            c.Expr[Unit] = ...
\end{lstlisting}

In the above, the arguments of \verb|assert_impl| of \verb|Expr| are syntax
trees, which the body of \verb|assert_impl| will operate on, itself returning
an AST of type \verb|Expr[Unit]|. It is \verb|assert_impl| which is
expanded and evaluated at compile-time, its result is then inlined at the
callsite of \verb|assert| and the inlined result is typechecked by the Scala
compiler. It is also important to note that implicit defs as described earlier
in Section \ref{sec:implicits} can be implemented as macros.

As we will see, these macros defs, coupled with implicits in Scala enable the
boilerplate-free usage of the Scala pickling framework at the pickling use-
site.

\paragraph{Macro Annotations.} Unlike macro defs, macro annotations are capable
of {\em adding members} to classes which carry their annotation.

\begin{lstlisting}
@withNewToString
class D { ... }
\end{lstlisting}

The \verb|withNewToString| annotation is defined using a standard class
definition by extending a special \verb|MacroAnnotation| marker trait, and by
implementing a special \verb|transform| method as a macro:

\begin{lstlisting}
class withNewToString extends MacroAnnotation {
  def transform = macro transform_impl
  def transform_impl = { ... }
}
\end{lstlisting}

The \verb|transform| macro implementation is passed the AST of the annotated class
definition (the AST of ``\verb|class D { ... }|''), and returns a possibly changed AST
as the new class definition (which could have added members, changed
constructor parameters etc.)

\section{Overview and Usage}
\label{sec:overview}

\section{Model of Object-Oriented Picklers}

In this section we provide a formal definition of object-oriented picklers. We
introduce picklers as first-class objects, and provide their type definitions
and contracts that valid implementations must uphold. Subsequently, we
demonstrate that the introduced picklers enable modular, object-oriented
pickler combinators, \ie methods for composing more complex picklers from
simpler primitive picklers.

Note that we are using a Scala-like program notation. However, the introduced
concepts and definitions are realizable in most statically-typed OO languages
with generics.

\begin{defn}(First-Class Picklers and Unpicklers)

A pickler for some type $T$ is an instance of one of two abstract class or
interface types \term{DPickler}$[T]$ or \term{SPickler}$[T]$. Each have an
abstract method \verb|pickle| with a single parameter of type $T$ and return
type \term{Pickle}:

\begin{lstlisting}
    trait DPickler[T] {
      def pickle(obj: T): Pickle
    }
\end{lstlisting}

\noindent(The type definition of \term{SPickler}$[T]$ differs only in the name of the type;
below we define the difference in their contracts.)

Conversely, an unpickler for some type $U$ is an instance of an abstract class
or interface type \term{Unpickler}$[U]$ that has a single abstract method
\verb|unpickle| with a single parameter of type \term{Pickle} and return type
\term{Unit}.
\end{defn}

The pickle method takes an object to-be-pickled of static type $T$, pickles it
by turning it into some external representation like a byte array, and returns
an instance of type \term{Pickle} which wraps the external representation. Given this
definition, picklers ``are type safe in the sense that a type-specialized
pickler can be applied only to values of the specialized type.''~\cite{Elsman2005}.

\paragraph{Preliminary Definitions.} To precisely specify the contracts of
picklers and unpicklers, we require standard definitions of the dynamic type
of an object \term{o}, written \itl{dynTypeOf(}\term{o}\itl{)}, and the erasure of a
static type $T$, written \itl{erasure(}$T$\itl{)}.

\begin{defn}(Structural Equality)

\noindent Two objects \term{obj}$_1$ and \term{obj}$_2$ are structurally equal, written

\begin{lstlisting}[escapechar=\%]
obj%$_1$% %$\equiv$% obj%$_2$%
\end{lstlisting}

\noindent if and only if

\begin{itemize}
\item \itl{dynTypeOf(}\term{obj$_1$}\itl{)} \term{=:=} \itl{dynTypeOf(}\term{obj$_2$}\itl{)} \term{=:=} $C$
      for some class type $C$, and we have that for all \term{fld} $\in$ $\textit{fields}(C)$.
      ~\term{obj$_1$.fld} $\equiv$ \term{obj$_2$.fld}, or
\item \itl{dynTypeOf(}\term{obj$_1$}\itl{)} \term{=:=} $T$ for some primitive type $T$, and \term{obj$_1$ == obj$_2$}.
\end{itemize}
\end{defn}

The contracts of \term{DPickler}s, \term{SPickler}s, and \term{Unpickler}s are
defined as follows.

\begin{defn}(Object-Oriented Picklers)

\noindent Given the following typed objects,

\begin{lstlisting}[escapechar=\%]
    dp: DPickler[%$T$%]
    sp: SPickler[%$T$%]
   obj: %$T$%
    up: Unpickler[%$U$%] %\textrm{where}% %$T <: U$%
  obj': %$T$%
\end{lstlisting}

\noindent where \term{obj} is the object to-be-pickled, and \term{obj'} is the unpickled
object. Then,

\begin{lstlisting}[escapechar=\%]
up.unpickle(dp.pickle(obj)) %\textrm{evaluates to}% obj'%\vspace{0.15cm}%
up.unpickle(sp.pickle(obj)) %\textrm{evaluates to}% obj' %\textrm{if}% dynTypeOf(obj) =:= erasure(T)
\end{lstlisting}

\noindent such that,

\begin{lstlisting}[escapechar=\%]
obj': U%\vspace{0.15cm}%
obj' %$\equiv$% obj
\end{lstlisting}
\end{defn}

Note that \term{SPickler}'s \term{pickle} method has a precondition which
requires the dynamic type of the object to-be-pickled to be equal to the
erasure of its static type $T$. This means that an \term{SPickler}$[T]$ is not
guaranteed to pickle any object of a subtype of $T$. Because of this
restriction we refer to instances of \term{SPickler} as {\em static picklers}.
In contrast, a \term{DPickler}$[T]$ pickles any object of type $T$. Therefore,
we refer to instances of \term{DPickler} as {\em dynamic picklers}.

In the following section, we motivate the distinction between static and
dynamic picklers.

\subsection{Modular Pickler Combinators}

Picklers as first-class objects make it possible to define pickler
combinators, which in turn make it possible to build compound picklers from
primitive picklers. However, only using the interface introduced above would
not allow us to achieve this, since calling into any of the component picklers
would produce a completed pickle; we would be left with the problem of
composing completed pickles which is inefficient in general. Since one of our
goals is high performance, we'll instead allow picklers to produce {\em
partial pickles} which themselves are essentially builders \cite{Gamma1995}
that multiple picklers can output to. The corresponding method has the
following signature:

\begin{lstlisting}
def pickle(obj: T, builder: PickleBuilder): Unit
\end{lstlisting}

\verb|PickleBuilder| has methods to incrementally add elements of an object
to-be-pickled to a pickle that is being constructed (see Section
\ref{sec:picklebuilder}). When all elements have been added to a
\verb|PickleBuilder|, calling \verb|result| returns the completed pickle.

For example, consider a simple class \verb|Position| with a field of type
String and a field of type \term{Person}, respectively:

\begin{lstlisting}
class Position(val title: String, val person: Person)
\end{lstlisting}

Modular pickler combinators would enable the composition of the desired
pickler for type \term{Position} from picklers for types \term{String} and
\term{Person}. However, note that the \term{person} field of a given instance
of class \term{Position} could point to an instance of a subclass of
\term{Person} (assuming class \term{Person} is not final). Therefore, a
modularly re-usable pickler for type \term{Person} must be able to pickle all
possible subtypes of \term{Person}.

In this case, the contract of static picklers is too strict, it does not allow
for subtyping. The contract of dynamic picklers on the other hand does allow
for subtyping. As a result, {\em dynamic picklers are necessary so as to enable
modular composition in the presence of subtyping}.

Picklers for final class types like \term{String}, or for primitive types like
\term{Int} do not require support for subtyping. Therefore, static picklers
are sufficient to pickle these {\em effectively final types}. Compared to
dynamic picklers, static picklers benefit from several optimizations that we
outline in more detail in Section~\ref{sec:optimize}.

\subsection{Implementing Object-Oriented Picklers}

The main challenge when implementing OO picklers comes from the fact that a
dynamic pickler for type $T$ must be able to pickle objects of any subtype of
$T$. Thus, the implementation of a dynamic pickler for type $T$ must, in
general, dynamically dispatch on the runtime type of the object to-be-pickled
to take into account all possible subtypes of $T$. Because of this dynamic
dispatch, manually constructing dynamic picklers can be difficult. It is
therefore important for a framework for object-oriented picklers to provide
good support for realizing this form of dynamic dispatching.

There are various ways across many different object-oriented programming
languages to handle subtypes of the pickler's static type:

\begin{itemize}
\item Data structures with shallow class hierarchies, such as lists or trees,
often have few final leaf classes. As a result, manual dispatch code is
typically simple in such cases. For example, a manual pickler for Scala's
\term{List} class does not even have to consider subclasses.

\item Java-style runtime reflection can be used to provide a generic
\term{DPickler}[$Any$] which supports pickling objects of any
type~\cite{JavaSerialization,Philippsen2000}. Such a pickler can be used as a
fallback to handle subtypes that are unknown to the pickling code; such
subtypes must be handled in the presence of separate compilation. In
Section\ref{sec:runtime-pickler} we present Scala implementations of such a
generic pickler.

\item Java-style annotation processing is commonly used to trigger the
generation of additional methods in annotated class types. The purpose of
generated methods for pickling would be to return a pickler or unpickler
specialized for an annotated class type. In C\#, the Roslyn
Project~\cite{Roslyn} allows augmenting class definitions based on the
presence of annotations.

\item Static meta programming \cite{Burmako2012,Nemerle} enables generation of
picklers at compile time. In Section~\ref{sec:generation} we present an
approach for generating object-oriented picklers from regular (class) type
definitions.
\end{itemize}

\subsection{Supporting Unanticipated Evolution}

Given the fact that the type \term{SPickler}[$T$], as introduced, has a type
parameter $T$, it is reasonable to ask what the variance of $T$ is. Ruling out
covariance because of $T$'s occurrence in a contravariant position as the type
of a method parameter, it remains to determine whether $T$ can be
contravariant.

For this, it is useful to consider the following scenario. Assume $T$ is
declared to be contravariant, as in \term{SPickler}[$-T$]. Furthermore, assume
the existence of a public, non-final class \term{C} with a subclass \term{D}:

\begin{lstlisting}
    class C
    class D extends C
\end{lstlisting}

Initially, we might define a generic pickler for \term{C}:

\begin{lstlisting}
    implicit val picklerC = new SPickler[C] {
      def pickle(obj: C): Pickle = { ... }
    }
\end{lstlisting}

Because \term{SPickler}[$T$] is contravariant in its type parameter, instances
of \term{D} would be pickled using \term{picklerC}. There are several possible
extensions that might be unanticipated initially:

\begin{itemize}
\item Because the implementation details of class \term{D} change, instances
of \term{D} should be pickled using a dedicated pickler instead of
\term{picklerC}.

\item A subclass \term{E} of \term{C} is added which requires a dedicated
pickler, since \term{picklerC} does not know how to instantiate class \term{E}
(since class \term{E} did not exist when \term{picklerC} was written).
\end{itemize}

In both cases it is necessary to add a new, dedicated pickler for either an
existing subclass (\term{D}) or a new subclass (\term{E}) of \term{C}:

\begin{lstlisting}
implicit val picklerD = new SPickler[D] { ... }
\end{lstlisting}

However, when pickling an instance of class \term{D} this new pickler,
\term{picklerD}, would not get selected, even if the type of the object to-be-
pickled is statically known to be \term{D}. The reason is that
\term{SPickler}[$C$] $<:$ \term{SPickler}[$D$] because of contravariance which
means that \term{picklerC} is more specific than \term{picklerD}. As a result,
according to Scala's implicit look-up rules \term{picklerC} is selected when
an implicit object of type \term{SPickler}[$D$] is required. (Note that this
is the case even if \term{picklerD} is declared in a scope that has higher
precedence than the scope in which \term{picklerC} is declared.)

While contravariant picklers do not support the two scenarios for
unanticipated extension outlined above, invariant picklers do, in combination
with type bounds. Assuming invariant picklers, we can define a generic method
\term{picklerC1} that returns picklers for all subtypes of class \term{C}
(including class \term{C} itself):


\begin{lstlisting}
implicit def picklerC1[T <: C] = new SPickler[T] {
  def pickle(obj: T): Pickle = { ... }
}
\end{lstlisting}

With this pickler in scope, it is still possible to define a more specific
\term{SPickler}[$D$] (or \term{SPickler}[$E$]) as required:

\begin{lstlisting}
implicit val picklerD1 = new SPickler[D] { ... }
\end{lstlisting}

However, the crucial difference is that now \term{picklerD1} is selected when
an object of static type \term{D} is pickled, since \term{picklerD1} is more
specific than \term{picklerC1}.

\subsection{Summary}

This section has introduced an object-oriented model of first-class picklers.
Object-oriented picklers enable modular pickler combinators with support for
subtyping, thereby extending a well-known approach in functional programming.
The distinction between static and dynamic picklers enables optimizations for
final class types and primitive types. Object-oriented picklers can be
implemented using various techniques, such as manually-written picklers,
runtime reflection, or Java-style annotation processors. Finally, we argue
that object-oriented picklers should be invariant in their generic type
parameter to allow for several scenarios of unanticipated evolution.





\subsection{Runtime Picklers}

\todo what to do with this?

One goal of our framework is to generate as much pickling code at compile time as possible. However, due to the interplay of subclassing with both separate compilation and generics, we provide a runtime fall back capability to handle the cases that cannot be resolved at compile time.

{\bf Subclassing and separate compilation}: A situation arises where it's impossible to know statically all possible subclasses. In this case there are three options: (1) provide a custom pickler, and (2) use an annotation which is described in Section ??. In the case where neither a custom pickler nor an annotation is provided, our framework can inspect the instance to-be-pickled at runtime to obtain the pickling logic. This comes with some runtime overhead, but in Section ?? we present results which suggest that this overhead is not necessary in many cases.

{\bf Subclassing and generics}: The combination of subclassing and generics poses a similar problem. For example, consider a generic class C,

\begin{verbatim}
    class C[T](val fld: T) { ... }
\end{verbatim}

A Pickler[C[T]] will not be able to pickle the field fld if its static type is unknown. To support pickling instances of generic classes, our framework falls back to using runtime picklers for pickling fields of generic type. So, when we have access to the runtime type of field fld, we can either look up an already generated pickler for that runtime type, or we can generate a suitable pickler dynamically. For the generation of runtime picklers our framework supports two possible strategies:

\begin{itemize}
\item Runtime interpretation of a type-specialized pickler
\item Runtime compilation of a type-specialized pickler
\end{itemize}

Interpreted runtime picklers. If the runtime type of an object is unknown at compile time, e.g., if its static type is Any, it is necessary to carry out the pickling based on inspecting the type of the object to-be-pickled at runtime. We call picklers operating in this mode "interpreted runtime picklers" to emphasize the fact that the pickling code is not partially evaluated in this case. An interpreted pickler is created based on the runtime class of the picklee. From that runtime class it is possible to obtain a runtime type descriptor of type ru.Type (ru is the so-called "runtime universe" of Scala's mirror-based reflection framework; compile-time reflection, aka macros, use compile-time universes). This runtime type is used

\begin{itemize}
\item to build a static intermediate representation of the type (which describes all its fields with their types, etc.)
\item to determine in which way the picklee should be pickled (as a primitive or not).
\end{itemize}

In case the picklee is of primitive type, there are no fields to be pickled. Otherwise, the value and runtime type of each field is obtained, so that it can be written to the pickle.

\subsection{Recursive Types}

\todo what to do with this?

Recursive types are used in many common data structures like lists, trees etc. Here we show how recursive types are supported in our framework.

Example (we show a non-generic class hierarchy for simplicity):

\begin{verbatim}
    abstract class IntTree
    class Empty extends IntTree
    class Fork(left: IntTree, elem: Int, right: IntTree)
\end{verbatim}

\subsection{Generics}

\todo what to do with this?

Our framework uses a hybrid static/dynamic approach to pickling generic types (i.e., parameterized types), depending on the type information that's statically available.

Pickling. Assume obj is an instance of a generic class C[T] with type parameter T. When pickling obj we can use TypeTags in Scala to reify the full static type of obj, including its type arguments, which are guaranteed to be concrete. However, thanks to subtyping, it's possible that obj is pickled using a static supertype of C[T], say, Base:

\begin{verbatim}
    class Base { ... }
    class C[T](val x: T) extends Base { ... }
    val obj: Base = new C[Int]
    obj.pickle
\end{verbatim}

As a result, only the runtime type information of obj is available for generating its pickler.

% \section{Generating Fast Picklers}

% \subsection{Front-end}

\section{Extensibility}
% \section{Pluggable Pickling Formats}

\todo what to do with this?

Our pickling framework is extensible in several dimensions:

\begin{enumerate}
\item [The following depends on implicits!] By design our framework enables defining picklers for existing classes that have not been written with pickling in mind. That way, a class hierarchy provided by a 3rd party can be equipped with a set of picklers retroactively. The following section shows how this form of extensibility is enabled by an object-oriented form of the typeclass design pattern in Scala.
\item Custom pickling formats.
\item Can show JSON as alternative to default binary format
\item Custom picklers. Customize what parts of an object are pickled and how. For example, a custom pickler for a particular collection type.
\end{enumerate}

\section{Implementation}

\begin{verbatim}
implicitly[Pickler[Person]](ps: Pickler[String], pi: Pickler[Int])
\end{verbatim}

it takes a Pickler[String] and a Pickler[Int] and produces a Pickler[Person].

to pickle an instance of a collection

\begin{verbatim}
obj.pickle[U]
\end{verbatim}

expands to

\begin{verbatim}
val pickler = obj.getClass match {
   case .. => Pickler[S]
}
pickler.pickle(obj)
\end{verbatim}

According to Liskov substitution

Are they composable? How?

Other Questions:
What do we do with the comparison between FP PCs and OO PCs?


which can be applied to objects of type T. That would mean also all subtypes of T. Likewise, an OO unpickler


In functional programming, pickling is supported using the well-known framework of pickler combinators. A pickler of type PU[A] (using Scala notation) can be used to pickle and unpickle values of type A.

Classical FP pickler combinators can't deal with:

subtyping


Other frameworks like Kryo?

[what about versioning issues?]

Our framework is designed to make simple tasks easy and difficult tasks possible. For example, consider the definition of a simple Scala class Person with name and age fields:

\begin{verbatim}
    class Person(val name: String, val age: Int) { ... }
\end{verbatim}

As you can see, the name and age fields are declared in the class parameter list. Class parameters in Scala are normally just the parameters of the primary constructor; adding the modifier val turns them into public fields.

To pickle an instance of this class using our framework, it is sufficient to import (the members of) our pickling package, and invoke the pickle extension method:

\begin{verbatim}
    import scala.pickling._
    val joe = new Person("Joe", 43)
    val pickle = joe.pickle
\end{verbatim}

Notice that the Person class does not have to carry a special annotation or extend a special interface type.\footnote{In Scala, Java-style interfaces are subsumed by traits that can be modularly extended using mix-in composition.} Instead, a suitable pickler is generated on-the-fly and is applied to instance joe to produce a pickled representation.

The above example seems to suggest that our framework requires extensions to the Scala language and compiler to enable this kind of seamless pickling support. However, this is not the case; in fact, our pickling framework relies only on features available in the mainline Scala compiler (version 2.10.x or later).

In the following sections we are going to answer in detail the following questions:

\begin{itemize}
\item Which types are pickleable such that the above pickle extension method can be used?
\item How does our framework automatically generate type-specialized picklers?
\end{itemize}

Idea: generating type class pattern using macros. We're generating type class instances based on existing type class instances using macros. A (new?) pattern that we use.

Section on simulating deriving type classes using macros in Scala. This requires more knowledge about deriving type classes in Haskell.

\section{Experimental Evaluation}

{\bf Microbenchmarks}

\begin{itemize}
\item individual types that are common
\item evaluate on microbenchmarks
\item look at size of pickles
\item look at bytecode size
\item TODO: tuples and maps
\end{itemize}

{\bf Real apps}
\begin{itemize}
\item TODO: find possible distributed apps using Akka or Spark
\item Samira's list: http://actor-applications.cs.illinois.edu/akka.html (cite her ECOOP paper)
apps should be heavy on serialization
\item finding apps:
(1) GeoTrellis (https://github.com/geotrellis/geotrellis)
GeoTrellis is an open source high performance geoprocessing engine that transforms user interaction with geospatial data through speed and scale.
Types (Java Serialization):
final case class DoubleConstant(n: Double, cols: Int, rows: Int) extends StrictRasterData

final case class IntConstant(n: Int, cols: Int, rows: Int) extends StrictRasterData

final case class BitArrayRasterData(array: Array[Byte], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

final case class ByteArrayRasterData(array: Array[Byte], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

final case class DoubleArrayRasterData(array: Array[Double], cols: Int, rows: Int) extends MutableRasterData with DoubleBasedArray

final case class FloatArrayRasterData(array: Array[Float], cols: Int, rows: Int) extends MutableRasterData with DoubleBasedArray

final case class IntArrayRasterData(array: Array[Int], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

final case class ShortArrayRasterData(array: Array[Short], cols: Int, rows: Int) extends MutableRasterData with IntBasedArray

Comments: MutableRasterData and IntBasedArray are just traits that do not contain data.

Can we get a GeoTrellis app to run?

\item SignalCollect
\item Socko (web server)
\item BigBlueButton (Java-based?)
\item Kevoree (framework for distribution)
\item SCADS
\end{itemize}

{\bf Survey of apps}

\begin{itemize}
\item take 10 or so apps, look at which types are pickled. Then we say which ones we support. and then we can point to microbenchmarks to show how it performs for that type.
\item first step: find real apps that are distributed
\item check Samira's paper, she has pointed out which actor apps are distributed
\item for Spark: every Spark is distributed, so we just have to find out which types are put into the RDDs. These element types are the ones we need to serialize.
\end{itemize}


% \appendix
% \section{Appendix Title}

% This is the text of the appendix, if you need one.

% \acks

% Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

%\begin{thebibliography}{}
%\softraggedright

%\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
%P. Q. Smith, and X. Y. Jones. ...reference text...

%\end{thebibliography}

\bibliography{bib}

\end{document}
