% \section{Old}

% \subsection{Old Intro}

% % From the ivory tower, it may not be evident,
% % It might not seem this way from the ivory tower,
% % but

% While it might not seem that way at a glance, mainstream software development
% has become largely distributed. Two {\em styles} of distribution dominate the
% current landscape; (1) systems composed of microservices, % or designed to be
% software as a service (SaaS), and (2) systems for ``big data'' processing.
% Names like Netflix, SoundCloud, and Twitter have established their
% competitive offerings by way of one or both of these types of systems.

% Microservices are small, independent (separately-compiled) services running
% on different machines which communicate with each other to together make up a
% single and complex application. ``Big data''-style applications on the other
% hand are typically single applications whose data cannot fit into the memory
% of one machine alone. Such applications are typically singly-compiled, with
% their binaries distributed across a cluster of machines.

% Yet, software developers still fumble with low-level RPC frameworks.  % and
% sluggish serialization frameworks.  Mainstream programming languages have
% traditionally offered little support in this space.

% We design module systems, etc, for maximum reuse and productivity, we go as
% far as we can to demonstrate their power. But we often . Some of these
% concerns have been affectionately referred to as the ``awkward
% squad''~\cite{AwkwardSquad} by PL research, and they are concerns that are
% central to contemporary software development.

% Functional programming brings value to distributed systems builders. The
% success of popular Spark can be attributed to functional ideas.

% However, beyond Spark's interface, .

% We refer to the model as {\em function-passing}, and .

% We design a programming model in such a way that we can ``maximize'' static
% types, and with it enable type-specialized picklers (statically generated),
% typed closures, and type-specialized data structures.

% The motto is ``making type inference work for you when optimizing distributed
% systems'', or ``how type inference and existential types benefit distributed
% systems''.

% In existing systems, types are only in the user-facing API and help the user.
% However, all too often, the internals of a distributed system are largely
% untyped, in particular when operating on data types that are also shipped
% remotely. In our approach we now go ahead and make types work so that they
% benefit both users (helping catch common errors) \emph{and} distributed
% systems builders. Our approach leverages types to provide (1)
% type-specialized picklers, and (2) type-specialized collections/builders.

% The approach is novel, because noone talks about making sure the unpicklers
% and builders themselves are serializable, but that's actually fundamental to
% the whole design.

% \begin{itemize}

% \item We have to make the point that serialization is like a primitive in
% systems design, not some extra thing you figure out how to do later, like in
% typical PLs. so maybe one central point that we should try to make is that
% for distributed systems, serializability is like a key primitive, along with
% latency and other things.

% \item we want to prove that typed distributed systems are a good idea. right
% now a lot of systems for dist computing are fundamentally untyped or
% dynamically checked. those that are typed lose type information between
% machines.

% \item so we're trying to argue that types are good for system builders.

% \end{itemize}

% The fact that actually these benefits from types \emph{carry over to other
% models as well} (not just spark-like models).

% Generalization of MapReduce model. Low-level. Inversion of the actor model.
% Can represent different many models for distributed computing, e.g. Spark,
% Percolator (we probably can't validate this claim.)

% Illustrations to have:
% \begin{enumerate}
% \item nice figure
% \item organic evolving model on youtube
% \end{enumerate}

% \subsection{Evaluation}

% we could make the performance eval strong by saying, ok, we implemented real
% apps, so we have the real communication that needs to happen (and happens).
% and we now make this communication typed, plus we measure exactly the
% percentage of time that's spent in serialization for example. and then we
% could even interpolate the results, so we could say, ok, if some other dist
% system has a lower percentage spent in serialization, then the speed up would
% be like this.

% and then we could even measure that for real spark, and then interpolate and
% say, ok, in the ideal case, meaning using all of our design principles, we
% could speed up things like this, if one would re-architect spark to preserve
% types (it's a huge task, so out of scope).

% well, it would definitely be something that we can measure objectively. the
% only thing we have to guard against would be to say, adding picklers and
% builders does not otherwise \emph{degrade} performance, like, we'd have to
% prove that there's no cost, but \emph{just} the performance benefits. adding
% the classname of the unpickler adds a few bytes to each pickle, for example.

% we could even show that with babyspark, like have a version that uses java
% serialization, then a version that uses pickling without selfdescribing, then
% with runtime unpickling, and with all static. because we have those numbers
% for babyspark then the interpolation will be much more precise.
